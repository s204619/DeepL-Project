{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: numpy in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: tqdm in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (4.67.0)\n",
      "Requirement already satisfied: transformers in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (4.46.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from torch) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/c-hasselris/DeepL/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install torch torchvision torchaudio numpy tqdm transformers scikit-learn #pickle5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==1.6.0 tensorflow==1.15.0 horovod==0.19.5 transformers==3.0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c-hasselris/DeepL/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sys.path.insert(0, './PLM-NR')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from utils import MODEL_CLASSES\n",
    "from tnlrv3.tokenization_tnlrv3 import TuringNLRv3Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c-hasselris/DeepL/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2107: FutureWarning: Calling TuringNLRv3Tokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "path_turing = './tnlrv3/'\n",
    "tokenizer = TuringNLRv3Tokenizer.from_pretrained(\"/Users/c-hasselris/Desktop/DeepLearning/DeepL-Project/Tiny-NewsRec/tnlrv3/tokenizer/tnlrv3-base-uncased-vocab.txt\",\n",
    "                                                 do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.news_query_vector_dim = 200\n",
    "        self.drop_rate = 0.2\n",
    "        self.news_dim = 256\n",
    "        self.num_hidden_layers = 4\n",
    "        self.corpus_path = './docs_filter.tsv'\n",
    "        self.num_teachers = 4\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TITLE_LEN = 24\n",
    "MAX_BODY_LEN = 512\n",
    "NPRATIO=9\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(args.corpus_path, encoding='utf-8') as f:\n",
    "    total_lines = f.readlines()\n",
    "len(total_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, bodies = [], []\n",
    "for line in total_lines:\n",
    "    splited = line.strip('\\n').split('\\t')\n",
    "    titles.append(splited[3])\n",
    "    bodies.append(splited[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './teacher_title_emb_0.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m title_scorings, body_scorings \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mnum_teachers):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./teacher_title_emb_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         title_scorings\u001b[38;5;241m.\u001b[39mappend(pickle\u001b[38;5;241m.\u001b[39mload(f))\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./teacher_body_emb_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/DeepL/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './teacher_title_emb_0.pkl'"
     ]
    }
   ],
   "source": [
    "# Must run Domain-specific_Post-train.ipynb first\n",
    "title_scorings, body_scorings = [], []\n",
    "for i in range(args.num_teachers):\n",
    "    with open(f'./teacher_title_emb_{i}.pkl', 'rb') as f:\n",
    "        title_scorings.append(pickle.load(f))\n",
    "    with open(f'./teacher_body_emb_{i}.pkl', 'rb') as f:\n",
    "        body_scorings.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillDataset(Dataset):\n",
    "    def __init__(self, titles, bodies, teacher_titles, teacher_bodies):\n",
    "        self.titles = titles\n",
    "        self.bodies = bodies\n",
    "        self.teacher_titles = teacher_titles\n",
    "        self.teacher_bodies = teacher_bodies\n",
    "        self.len = len(titles)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        select_list = list(range(0, idx)) + list(range(idx+1, self.len))\n",
    "        neg_idx = random.sample(select_list, NPRATIO)\n",
    "        neg_titles = [self.titles[i] for i in neg_idx]\n",
    "        pos_title = self.titles[idx]\n",
    "        titles = [tokenizer(title, max_length=MAX_TITLE_LEN, pad_to_max_length=True,\n",
    "                            truncation=True) for title in [pos_title] + neg_titles]\n",
    "        input_titles = np.array([title['input_ids'] + title['attention_mask'] for title in titles])\n",
    "        body = tokenizer(self.bodies[idx], max_length=MAX_BODY_LEN, pad_to_max_length=True,\n",
    "                        truncation=True)\n",
    "        input_body = np.array(body['input_ids'] + body['attention_mask'])\n",
    "                                 \n",
    "        total_idx = [idx] + neg_idx\n",
    "        input_teacher_titles = [x[total_idx] for x in self.teacher_titles]\n",
    "        input_teacher_bodies = [x[idx] for x in self.teacher_bodies]\n",
    "        label=0\n",
    "        return input_titles, input_body, label, input_teacher_titles, input_teacher_bodies\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_ds = DistillDataset(titles, bodies, title_scorings, body_scorings)\n",
    "distill_dl = DataLoader(distill_ds, batch_size=BATCH_SIZE, num_workers=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(emb_size, hidden_size)\n",
    "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch_size, candidate_size, emb_dim\n",
    "            attn_mask: batch_size, candidate_size\n",
    "        Returns:\n",
    "            (shape) batch_size, emb_dim\n",
    "        \"\"\"\n",
    "        bz = x.shape[0]\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "        alpha = torch.exp(alpha)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "        \n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha).squeeze(dim=-1)\n",
    "        return x\n",
    "\n",
    "class NewsEncoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(NewsEncoder, self).__init__()\n",
    "        config_class, model_class, tokenizer_class = MODEL_CLASSES['tnlrv3']\n",
    "        self.bert_config = config_class.from_pretrained(\n",
    "            os.path.join(path_turing, 'unilm2-base-uncased-config.json'), \n",
    "            output_hidden_states=True,\n",
    "            num_hidden_layers=args.num_hidden_layers)\n",
    "        self.bert_model = model_class.from_pretrained(\n",
    "            os.path.join(path_turing, 'unilm2-base-uncased.bin'), config=self.bert_config)\n",
    "        self.attn = AttentionPooling(self.bert_config.hidden_size, args.news_query_vector_dim)\n",
    "        self.dense = nn.Linear(self.bert_config.hidden_size, args.news_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x: batch_size, word_num * 2\n",
    "            mask: batch_size, word_num\n",
    "        '''\n",
    "        batch_size, num_words = x.shape\n",
    "        num_words = num_words // 2\n",
    "        text_ids = torch.narrow(x, 1, 0, num_words)\n",
    "        text_attmask = torch.narrow(x, 1, num_words, num_words)\n",
    "        word_vecs = self.bert_model(text_ids, text_attmask)[3][self.bert_config.num_hidden_layers]\n",
    "        news_vec = self.attn(word_vecs)\n",
    "        news_vec = self.dense(news_vec)\n",
    "        return news_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleBodySimModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(TitleBodySimModel, self).__init__()\n",
    "        self.news_encoder = NewsEncoder(args)\n",
    "        \n",
    "    def forward(self, title, body):\n",
    "        '''\n",
    "            title: bz, 1+K, MAX_TITLE_WORD * 2\n",
    "            body: bz, MAX_BODY_WORD * 2\n",
    "            labels: bz\n",
    "        '''\n",
    "        body_emb = self.news_encoder(body)             #bz,emb_dim\n",
    "        bz, candi_num, input_num = title.shape\n",
    "        title = title.reshape(-1, input_num)\n",
    "        title_emb = self.news_encoder(title)\n",
    "        title_emb = title_emb.reshape(bz, candi_num, -1) #bz, 1+K, emb_dim\n",
    "        \n",
    "        scores = torch.bmm(title_emb, body_emb.unsqueeze(dim=-1)).squeeze(-1)\n",
    "        \n",
    "        return scores, title_emb, body_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kd_ce_loss(logits_S, logits_T, temperature=1):\n",
    "    '''\n",
    "    Calculate the cross entropy between logits_S and logits_T\n",
    "    :param logits_S: Tensor of shape (batch_size, length, num_labels) or (batch_size, num_labels)\n",
    "    :param logits_T: Tensor of shape (batch_size, length, num_labels) or (batch_size, num_labels)\n",
    "    :param temperature: A float or a tensor of shape (batch_size, length) or (batch_size,)\n",
    "    '''\n",
    "    beta_logits_T = logits_T / temperature\n",
    "    beta_logits_S = logits_S / temperature\n",
    "    p_T = F.softmax(beta_logits_T, dim=-1)\n",
    "    loss = -(p_T * F.log_softmax(beta_logits_S, dim=-1)).sum(dim=-1).mean()\n",
    "    return loss\n",
    "\n",
    "def hid_mse_loss(state_S, state_T, mask=None, reduce=True):\n",
    "    '''\n",
    "    * Calculates the mse loss between `state_S` and `state_T`, which are the hidden state of the models.\n",
    "    * If the `inputs_mask` is given, masks the positions where ``input_mask==0``.\n",
    "    * If the hidden sizes of student and teacher are different, 'proj' option is required in `inetermediate_matches` to match the dimensions.\n",
    "    :param torch.Tensor state_S: tensor of shape  (*batch_size*, *length*, *hidden_size*)\n",
    "    :param torch.Tensor state_T: tensor of shape  (*batch_size*, *length*, *hidden_size*)\n",
    "    :param torch.Tensor mask:    tensor of shape  (*batch_size*, *length*)\n",
    "    '''\n",
    "    if mask is None:\n",
    "        if not reduce:\n",
    "            loss = F.mse_loss(state_S, state_T, reduction='none').mean(dim=-1)\n",
    "        else:\n",
    "            loss = F.mse_loss(state_S, state_T)\n",
    "    else:\n",
    "        if not reduce:\n",
    "            loss = (F.mse_loss(state_S, state_T, reduction='none') *\n",
    "                    mask.unsqueeze(-1)).mean(dim=-1)\n",
    "        else:\n",
    "            valid_count = mask.sum() * state_S.size(-1)\n",
    "            loss = (F.mse_loss(state_S, state_T, reduction='none') *\n",
    "                    mask.unsqueeze(-1)).sum() / valid_count\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(DistillModel, self).__init__()\n",
    "        self.student = TitleBodySimModel(args)\n",
    "        self.target_loss = nn.CrossEntropyLoss()\n",
    "        self.distill_loss = kd_ce_loss\n",
    "        self.emb_loss = hid_mse_loss\n",
    "        self.transform_matrix = nn.ModuleList([nn.Linear(args.news_dim, args.news_dim) for _ in range(args.num_teachers)])\n",
    "        for module in self.transform_matrix:\n",
    "            nn.init.xavier_uniform_(module.weight, gain=1.)\n",
    "            nn.init.constant_(module.bias, 0.0)\n",
    "\n",
    "    def forward(self, title, body, labels, teacher_titles, teacher_bodies):\n",
    "        '''\n",
    "            teacher_titles: [(batch_size, 1+K, news_emb) * num_teachers]\n",
    "            teacher_bodies: [(batch_size, news_emb) * num_teachers]\n",
    "        '''\n",
    "        student_score, student_title, student_body = self.student(title, body)\n",
    "        target_loss = self.target_loss(student_score, labels)\n",
    "\n",
    "        teacher_scores, teacher_losses, teacher_MSEs = [], [], []\n",
    "        for i, (teacher_title, teacher_body) in enumerate(zip(teacher_titles, teacher_bodies)):\n",
    "            teacher_score = torch.bmm(teacher_title, teacher_body.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
    "            teacher_loss = F.cross_entropy(teacher_score, labels, reduction='none')\n",
    "            teacher_scores.append(teacher_score)\n",
    "            teacher_losses.append(teacher_loss)\n",
    "\n",
    "            teacher_title_proj = self.transform_matrix[i](teacher_title)\n",
    "            teacher_body_proj = self.transform_matrix[i](teacher_body)\n",
    "            teacher_MSE = \\\n",
    "                self.emb_loss(student_title, teacher_title_proj, reduce=False).mean(dim=-1) + \\\n",
    "                    self.emb_loss(student_body, teacher_body_proj, reduce=False)\n",
    "            teacher_MSEs.append(teacher_MSE)\n",
    "\n",
    "        teacher_losses = - torch.stack(teacher_losses, dim=-1)\n",
    "        teacher_weights = F.softmax(teacher_losses, dim=-1)\n",
    "\n",
    "        teacher_scores = torch.stack(teacher_scores, dim=-1)\n",
    "        teacher_scores = torch.bmm(teacher_scores, teacher_weights.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
    "        distill_loss = self.distill_loss(student_score, teacher_scores)\n",
    "        emb_loss = (teacher_MSEs * teacher_weights).sum(dim=-1).mean()\n",
    "\n",
    "        loss = target_loss + distill_loss + emb_loss\n",
    "        return loss, target_loss, distill_loss, emb_loss, student_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distill_model = DistillModel(args)\n",
    "device = torch.device('cuda')\n",
    "distill_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = torch.argmax(y_hat, dim=-1)\n",
    "    tot = y_true.shape[0]\n",
    "    hit = torch.sum(y_true == y_hat)\n",
    "    return hit.data.float() * 1.0 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in distill_model.student.news_encoder.bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for index, layer in enumerate(distill_model.student.news_encoder.bert_model.bert.encoder.layer):\n",
    "    if index in [2, 3]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "for name, p in distill_model.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_param = filter(\n",
    "    lambda x: id(x) not in list(map(id, distill_model.student.news_encoder.bert_model.parameters())), distill_model.parameters())\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    [{'params':distill_model.student.news_encoder.bert_model.parameters(),'lr':1e-6},\n",
    "    {'params':rest_param,'lr':1e-5}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ep in range(1):\n",
    "    loss, target_loss, distill_loss, emb_loss = 0.0, 0.0, 0.0, 0.0\n",
    "    accuary = 0.0\n",
    "    cnt = 1\n",
    "    tqdm_util = tqdm(distill_dl)\n",
    "    distill_model.train()\n",
    "    for title,body,labels,teacher_title,teacher_body in tqdm_util:\n",
    "        title = title.cuda(non_blocking=True)\n",
    "        body = body.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "        teacher_title = teacher_title.cuda(non_blocking=True)\n",
    "        teacher_body = teacher_body.cuda(non_blocking=True)\n",
    "        \n",
    "        bz_loss, t_loss, d_loss, e_loss, y_hat = distill_model(title, body, labels, teacher_title, teacher_body)\n",
    "        \n",
    "        loss += bz_loss.data.float()\n",
    "        target_loss += t_loss.data.float()\n",
    "        distill_loss += d_loss.data.float()\n",
    "        emb_loss += e_loss.data.float()\n",
    "        accuary += acc(labels, y_hat)\n",
    "        optimizer.zero_grad()\n",
    "        bz_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if cnt % 10 == 0:\n",
    "            tqdm_util.set_description('ed: {}, loss: {:.5f}, t_loss: {:.5f}, d_loss: {:.5f}, e_loss: {:.5f}, acc: {:.5f}'.format(\n",
    "                cnt * BATCH_SIZE, loss.data / cnt, target_loss.data / cnt, distill_loss.data / cnt, emb_loss.data / cnt, accuary / cnt))\n",
    "        \n",
    "        cnt += 1\n",
    "        \n",
    "    ckpt_path = f'./first_stage_{args.num_hidden_layers}_layer.pt'\n",
    "    torch.save({'model_state_dict': distill_model.state_dict()}, ckpt_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
