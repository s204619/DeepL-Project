{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 13536710/13536710 [13:15<00:00, 17025.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission file for: clicked_prediction_scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13536710it [02:08, 105368.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping downloads/predictions.txt to downloads/clicked_prediction_scores.zip\n",
      "Writing submission file for: inview_prediction_scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13536710it [02:08, 105657.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping downloads/predictions.txt to downloads/inview_prediction_scores.zip\n",
      "Writing submission file for: inview_estimate_prediction_scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13536710it [02:09, 104928.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping downloads/predictions.txt to downloads/inview_estimate_prediction_scores.zip\n",
      "Writing submission file for: readtime_prediction_scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13536710it [02:08, 104949.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping downloads/predictions.txt to downloads/readtime_prediction_scores.zip\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "\n",
    "from ebrec.utils._python import (\n",
    "    rank_predictions_by_score,\n",
    "    write_submission_file,\n",
    "    create_lookup_dict,\n",
    ")\n",
    "from ebrec.utils._constants import *\n",
    "\n",
    "PATH = Path(\"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/ebnerd_testset\").expanduser()\n",
    "\n",
    "df_behaviors = pl.scan_parquet(PATH.joinpath(\"test\", \"behaviors.parquet\"))\n",
    "df_articles = pl.scan_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "\n",
    "# ==== LOOKUP DICTS\n",
    "clicked_dict = create_lookup_dict(\n",
    "    df_articles.select(DEFAULT_ARTICLE_ID_COL, DEFAULT_TOTAL_PAGEVIEWS_COL).collect(),\n",
    "    DEFAULT_ARTICLE_ID_COL,\n",
    "    DEFAULT_TOTAL_PAGEVIEWS_COL,\n",
    ")\n",
    "inview_dict = create_lookup_dict(\n",
    "    df_articles.select(DEFAULT_ARTICLE_ID_COL, DEFAULT_TOTAL_INVIEWS_COL).collect(),\n",
    "    DEFAULT_ARTICLE_ID_COL,\n",
    "    DEFAULT_TOTAL_INVIEWS_COL,\n",
    ")\n",
    "readtime_dict = create_lookup_dict(\n",
    "    df_articles.select(DEFAULT_ARTICLE_ID_COL, DEFAULT_TOTAL_READ_TIME_COL).collect(),\n",
    "    DEFAULT_ARTICLE_ID_COL,\n",
    "    DEFAULT_TOTAL_READ_TIME_COL,\n",
    ")\n",
    "\n",
    "# Estimate:\n",
    "df_inview_estimate = (\n",
    "    df_behaviors.select(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "    .explode(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "    .select(pl.col(DEFAULT_INVIEW_ARTICLES_COL).value_counts())\n",
    "    .unnest(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "    .collect()\n",
    ")\n",
    "inview_dict_estimate = create_lookup_dict(\n",
    "    df_inview_estimate.select(DEFAULT_INVIEW_ARTICLES_COL, \"count\"),\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    \"count\",\n",
    ")\n",
    "\n",
    "# ==== CLICKED PREDICTIONS\n",
    "CLICKED_SCORE_COL = \"clicked_prediction_scores\"\n",
    "INVIEW_SCORE_COL = \"inview_prediction_scores\"\n",
    "INVIEW_ESTIMATE_SCORE_COL = \"inview_estimate_prediction_scores\"\n",
    "READTIME_SCORE_COL = \"readtime_prediction_scores\"\n",
    "\n",
    "df_predictions = (\n",
    "    df_behaviors.select(DEFAULT_IMPRESSION_ID_COL, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "        .list.eval(pl.element().replace(clicked_dict).fill_null(0))\n",
    "        .alias(CLICKED_SCORE_COL)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "        .list.eval(pl.element().replace(inview_dict).fill_null(0))\n",
    "        .alias(INVIEW_SCORE_COL)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "        .list.eval(pl.element().replace(inview_dict_estimate).fill_null(0))\n",
    "        .alias(INVIEW_ESTIMATE_SCORE_COL)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "        .list.eval(pl.element().replace(readtime_dict).fill_null(0))\n",
    "        .alias(READTIME_SCORE_COL)\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "# CONVERT TO RANKS:\n",
    "impression_id = []\n",
    "clicked_scores = []\n",
    "inview_scores = []\n",
    "inview_estimate_scores = []\n",
    "readtime_scores = []\n",
    "for row in tqdm(\n",
    "    df_predictions.iter_rows(named=True),\n",
    "    total=df_predictions.shape[0],\n",
    "    ncols=80,\n",
    "):\n",
    "    impression_id.append(row[DEFAULT_IMPRESSION_ID_COL])\n",
    "    clicked_scores.append(rank_predictions_by_score(row[CLICKED_SCORE_COL]))\n",
    "    inview_scores.append(rank_predictions_by_score(row[INVIEW_SCORE_COL]))\n",
    "    inview_estimate_scores.append(\n",
    "        rank_predictions_by_score(row[INVIEW_ESTIMATE_SCORE_COL])\n",
    "    )\n",
    "    readtime_scores.append(rank_predictions_by_score(row[READTIME_SCORE_COL]))\n",
    "\n",
    "#\n",
    "for col, scores in zip(\n",
    "    [\n",
    "        CLICKED_SCORE_COL,\n",
    "        INVIEW_SCORE_COL,\n",
    "        INVIEW_ESTIMATE_SCORE_COL,\n",
    "        READTIME_SCORE_COL,\n",
    "    ],\n",
    "    [clicked_scores, inview_scores, inview_estimate_scores, readtime_scores],\n",
    "):\n",
    "    print(\"Writing submission file for:\", col)\n",
    "    Path(\"downloads\").mkdir(exist_ok=True)\n",
    "    write_submission_file(\n",
    "        impression_ids=impression_id,\n",
    "        prediction_scores=scores,\n",
    "        path=\"downloads/predictions.txt\",\n",
    "        filename_zip=f\"{col}.zip\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
