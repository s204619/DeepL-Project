{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "In this notebook, we illustrate how to use the Neural News Recommendation with Multi-Head Self-Attention ([NRMS](https://aclanthology.org/D19-1671/)). The implementation is taken from the [recommenders](https://github.com/recommenders-team/recommenders) repository. We have simply stripped the model to keep it cleaner.\n",
    "\n",
    "We use a small dataset, which is downloaded from [recsys.eb.dk](https://recsys.eb.dk/). All the datasets are stored in the folder path ```~/ebnerd_data/*```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 16:29:56.254649: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-19 16:29:56.300213: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-19 16:29:56.300248: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-19 16:29:56.300275: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-19 16:29:56.309634: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-19 16:29:57.622085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "import datetime\n",
    "\n",
    "from ebrec.utils._constants import *\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_prediction_scores,\n",
    "    add_known_user_column,\n",
    "    truncate_history,\n",
    ")\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel #, NRMSWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 16:29:59.537088: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Available devices:\", physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data\").expanduser()\n",
    "#\n",
    "DATASPLIT = \"ebnerd_small\"\n",
    "DUMP_DIR = Path(\"ebnerd_predictions\")\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History size can often be a memory bottleneck; if adjusted, the NRMS hyperparameter ```history_size``` must be updated to ensure compatibility and efficient memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_SIZE = 20\n",
    "hparams_nrms.history_size = HISTORY_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We just want to load the necessary columns\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "# This notebook is just a simple 'get-started'; we down sample the number of samples to just run quickly through it.\n",
    "FRACTION = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we sample the dataset, just to keep it smaller. We'll split the training data into training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(\n",
    "    path: Path,\n",
    "    history_size: int = 30,\n",
    "    padding: int = 0,\n",
    "    user_col: str = DEFAULT_USER_COL,\n",
    "    history_aids_col: str = DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(user_col, history_aids_col)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=history_aids_col,\n",
    "            history_size=history_size,\n",
    "            padding_value=padding,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=user_col,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1995\n",
      "Validation samples: 347\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>labels</th></tr><tr><td>u32</td><td>u32</td><td>datetime[Î¼s]</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>list[i8]</td></tr></thead><tbody><tr><td>586962</td><td>139550864</td><td>2023-05-19 16:05:47</td><td>[9768860, 9767534, â€¦ 9770867]</td><td>[9772029]</td><td>[9746360, 9768583, â€¦ 9772029]</td><td>[0, 0, â€¦ 1]</td></tr><tr><td>709317</td><td>17296567</td><td>2023-05-19 05:31:06</td><td>[9768829, 9767637, â€¦ 9770594]</td><td>[9771627]</td><td>[9771627, 9099237, â€¦ 9771119]</td><td>[1, 0, â€¦ 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ user_id â”† impression_i â”† impression_t â”† article_id_f â”† article_ids_ â”† article_ids_ â”† labels      â”‚\n",
       "â”‚ ---     â”† d            â”† ime          â”† ixed         â”† clicked      â”† inview       â”† ---         â”‚\n",
       "â”‚ u32     â”† ---          â”† ---          â”† ---          â”† ---          â”† ---          â”† list[i8]    â”‚\n",
       "â”‚         â”† u32          â”† datetime[Î¼s] â”† list[i32]    â”† list[i64]    â”† list[i64]    â”†             â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 586962  â”† 139550864    â”† 2023-05-19   â”† [9768860,    â”† [9772029]    â”† [9746360,    â”† [0, 0, â€¦ 1] â”‚\n",
       "â”‚         â”†              â”† 16:05:47     â”† 9767534, â€¦   â”†              â”† 9768583, â€¦   â”†             â”‚\n",
       "â”‚         â”†              â”†              â”† 9770867]     â”†              â”† 9772029]     â”†             â”‚\n",
       "â”‚ 709317  â”† 17296567     â”† 2023-05-19   â”† [9768829,    â”† [9771627]    â”† [9771627,    â”† [1, 0, â€¦ 0] â”‚\n",
       "â”‚         â”†              â”† 05:31:06     â”† 9767637, â€¦   â”†              â”† 9099237, â€¦   â”†             â”‚\n",
       "â”‚         â”†              â”†              â”† 9770594]     â”†              â”† 9771119]     â”†             â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(DATASPLIT, \"train\"),\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding=0,\n",
    "    )\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "dt_split = pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL).max() - datetime.timedelta(days=1)\n",
    "df_train = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) < dt_split)\n",
    "df_validation = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) >= dt_split)\n",
    "\n",
    "print(f\"Train samples: {df_train.height}\\nValidation samples: {df_validation.height}\")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set\n",
    "We'll use the validation set, as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m PATH\u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexpanduser()\n\u001b[1;32m      2\u001b[0m datasplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mebnerd_testset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m df_test \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mebnerd_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mPATH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# PATH.joinpath(DATASPLIT, \"validation\"),\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHISTORY_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mselect(COLUMNS)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mpipe(create_binary_labels_column)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# .sample(fraction=FRACTION)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mebnerd_from_path\u001b[0;34m(path, history_size, padding, user_col, history_aids_col)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mLoad ebnerd - function\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m df_history \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     12\u001b[0m     pl\u001b[38;5;241m.\u001b[39mscan_parquet(path\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39mselect(user_col, history_aids_col)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m df_behaviors \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     23\u001b[0m     pl\u001b[38;5;241m.\u001b[39mscan_parquet(path\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehaviors.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;241m.\u001b[39mpipe(\n\u001b[1;32m     26\u001b[0m         slice_join_dataframes,\n\u001b[0;32m---> 27\u001b[0m         df2\u001b[38;5;241m=\u001b[39m\u001b[43mdf_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     28\u001b[0m         on\u001b[38;5;241m=\u001b[39muser_col,\n\u001b[1;32m     29\u001b[0m         how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_behaviors\n",
      "File \u001b[0;32m/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/polars/lazyframe/frame.py:1935\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, no_optimization, streaming, background, _eager)\u001b[0m\n\u001b[1;32m   1932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m background:\n\u001b[1;32m   1933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InProcessQuery(ldf\u001b[38;5;241m.\u001b[39mcollect_concurrently())\n\u001b[0;32m-> 1935\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(ldf\u001b[38;5;241m.\u001b[39mcollect())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PATH= Path(\"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data\").expanduser()\n",
    "datasplit=\"ebnerd_testset\"\n",
    "\n",
    "df_test = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(datasplit, \"test\"),\n",
    "        # PATH.joinpath(DATASPLIT, \"validation\"),\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding=0,\n",
    "    )\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    # .sample(fraction=FRACTION)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[Î¼s]</td><td>bool</td><td>str</td><td>datetime[Î¼s]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var iâ€¦</td><td>&quot;Politiet frygtâ€¦</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den Ã¸â€¦</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars â€¦</td><td>&quot;BiografgÃ¦ngernâ€¦</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har â€¦</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Ã˜konomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ article_i â”† title     â”† subtitle  â”† last_modi â”† â€¦ â”† total_pag â”† total_rea â”† sentiment â”† sentimen â”‚\n",
       "â”‚ d         â”† ---       â”† ---       â”† fied_time â”†   â”† eviews    â”† d_time    â”† _score    â”† t_label  â”‚\n",
       "â”‚ ---       â”† str       â”† str       â”† ---       â”†   â”† ---       â”† ---       â”† ---       â”† ---      â”‚\n",
       "â”‚ i32       â”†           â”†           â”† datetime[ â”†   â”† i32       â”† f32       â”† f32       â”† str      â”‚\n",
       "â”‚           â”†           â”†           â”† Î¼s]       â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 3001353   â”† Natascha  â”† Politiet  â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.9955    â”† Negative â”‚\n",
       "â”‚           â”† var ikke  â”† frygter   â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† den       â”† nu, at    â”† 06:20:33  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† fÃ¸rste    â”† Nataschaâ€¦ â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 3003065   â”† Kun Star  â”† BiografgÃ¦ â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.846     â”† Positive â”‚\n",
       "â”‚           â”† Wars      â”† ngerne    â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† tjente    â”† strÃ¸mmer  â”† 06:20:35  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† mere      â”† ind forâ€¦  â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(DATASPLIT, \"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs.\n",
    "\n",
    "Note, with this ```NRMSDataLoader``` the ```eval_mode=False``` is meant for ```model.model.fit()``` whereas ```eval_mode=True``` is meant for ```model.scorer.predict()```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "print(\"Available devices:\", physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the NRMS-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 0s - loss: 1.6039\n",
      "Epoch 1: val_loss improved from inf to 1.61417, saving model to downloads/data/state_dict/NRMS/weights.weights.h5\n",
      "63/63 [==============================] - 74s 1s/step - loss: 1.6039 - val_loss: 1.6142\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "WEIGHTS_DIR = f\"downloads/data/state_dict/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = f\"{WEIGHTS_DIR}/weights.weights.h5\"\n",
    "\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "# CALLBACKS\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    ")\n",
    "\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=1,\n",
    "    callbacks=[early_stopping, modelcheckpoint]#tensorboard_callback\n",
    ")\n",
    "_ = model.model.load_weights(filepath=MODEL_WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "We will add some callbacks to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard:\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=LOG_DIR,\n",
    "    histogram_freq=1,\n",
    ")\n",
    "\n",
    "# Earlystopping:\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# ModelCheckpoint:\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS,\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Learning rate scheduler:\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "callbacks = [tensorboard_callback, early_stopping, modelcheckpoint, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 0s - loss: 1.5528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 16:46:19.617716: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 46080368640 exceeds 10% of free system memory.\n",
      "2024-12-19 16:46:28.098013: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 46080368640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,val_loss\n",
      "WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_auc` which is not available. Available metrics are: loss,val_loss,lr\n",
      "63/63 [==============================] - 83s 1s/step - loss: 1.5528 - val_loss: 1.6268 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "USE_CALLBACKS = True\n",
    "EPOCHS = 1\n",
    "\n",
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks if USE_CALLBACKS else [],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CALLBACKS:\n",
    "    _ = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3880890/1779326870.py\", line 3, in <module>\n",
      "    test_dataloader = NRMSDataLoader(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 13, in __init__\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/src/ebrec/models/newsrec/dataloader.py\", line 44, in __post_init__\n",
      "    self.X, self.y = self.load_data()\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/src/ebrec/models/newsrec/dataloader.py\", line 58, in load_data\n",
      "    y = self.behaviors[self.labels_col]\n",
      "        ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/polars/dataframe/frame.py\", line 1698, in __getitem__\n",
      "    return self.get_column(item)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/polars/dataframe/frame.py\", line 7050, in get_column\n",
      "    return wrap_s(self._df.get_column(name))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "polars.exceptions.ColumnNotFoundError: labels\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1428, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1319, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1172, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1062, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1154, in get_records\n",
      "    FrameInfo(\n",
      "  File \"/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 780, in __init__\n",
      "    ix = inspect.getsourcelines(frame)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/appl9/python/3.11.4/lib/python3.11/inspect.py\", line 1244, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/appl9/python/3.11.4/lib/python3.11/inspect.py\", line 1081, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE_TEST = 16\n",
    "\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 122s 794ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.scorer.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the predictions to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>labels</th><th>scores</th></tr><tr><td>u32</td><td>u32</td><td>datetime[Î¼s]</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>list[i8]</td><td>list[f64]</td></tr></thead><tbody><tr><td>983098</td><td>202907971</td><td>2023-05-28 20:43:01</td><td>[9775701, 9775983, â€¦ 9778939]</td><td>[9766514]</td><td>[9785349, 9785209, â€¦ 9780736]</td><td>[0, 0, â€¦ 0]</td><td>[0.479354, 0.453712, â€¦ 0.475159]</td></tr><tr><td>513401</td><td>569008456</td><td>2023-06-01 05:09:38</td><td>[9778804, 9778219, â€¦ 9778939]</td><td>[9790784]</td><td>[9484153, 9790825, â€¦ 9527795]</td><td>[0, 0, â€¦ 0]</td><td>[0.393523, 0.518457, â€¦ 0.357469]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 8)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ user_id â”† impression â”† impression â”† article_id â”† article_id â”† article_id â”† labels    â”† scores    â”‚\n",
       "â”‚ ---     â”† _id        â”† _time      â”† _fixed     â”† s_clicked  â”† s_inview   â”† ---       â”† ---       â”‚\n",
       "â”‚ u32     â”† ---        â”† ---        â”† ---        â”† ---        â”† ---        â”† list[i8]  â”† list[f64] â”‚\n",
       "â”‚         â”† u32        â”† datetime[Î¼ â”† list[i32]  â”† list[i32]  â”† list[i32]  â”†           â”†           â”‚\n",
       "â”‚         â”†            â”† s]         â”†            â”†            â”†            â”†           â”†           â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 983098  â”† 202907971  â”† 2023-05-28 â”† [9775701,  â”† [9766514]  â”† [9785349,  â”† [0, 0, â€¦  â”† [0.479354 â”‚\n",
       "â”‚         â”†            â”† 20:43:01   â”† 9775983, â€¦ â”†            â”† 9785209, â€¦ â”† 0]        â”† ,         â”‚\n",
       "â”‚         â”†            â”†            â”† 9778939]   â”†            â”† 9780736]   â”†           â”† 0.453712, â”‚\n",
       "â”‚         â”†            â”†            â”†            â”†            â”†            â”†           â”† â€¦         â”‚\n",
       "â”‚         â”†            â”†            â”†            â”†            â”†            â”†           â”† 0.475159] â”‚\n",
       "â”‚ 513401  â”† 569008456  â”† 2023-06-01 â”† [9778804,  â”† [9790784]  â”† [9484153,  â”† [0, 0, â€¦  â”† [0.393523 â”‚\n",
       "â”‚         â”†            â”† 05:09:38   â”† 9778219, â€¦ â”†            â”† 9790825, â€¦ â”† 0]        â”† ,         â”‚\n",
       "â”‚         â”†            â”†            â”† 9778939]   â”†            â”† 9527795]   â”†           â”† 0.518457, â”‚\n",
       "â”‚         â”†            â”†            â”†            â”†            â”†            â”†           â”† â€¦         â”‚\n",
       "â”‚         â”†            â”†            â”†            â”†            â”†            â”†           â”† 0.357469] â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = add_prediction_scores(df_test, pred_test.tolist())\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.5243153252658638,\n",
       "    \"mrr\": 0.32957706898653777,\n",
       "    \"ndcg@5\": 0.36306189378701875,\n",
       "    \"ndcg@10\": 0.44802213039224403\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=df_test[\"labels\"].to_list(),\n",
    "    predictions=df_test[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_clicked</th><th>article_ids_inview</th><th>labels</th><th>scores</th><th>ranked_scores</th></tr><tr><td>u32</td><td>u32</td><td>datetime[Î¼s]</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>list[i8]</td><td>list[f64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>983098</td><td>202907971</td><td>2023-05-28 20:43:01</td><td>[9775701, 9775983, â€¦ 9778939]</td><td>[9766514]</td><td>[9785349, 9785209, â€¦ 9780736]</td><td>[0, 0, â€¦ 0]</td><td>[0.479354, 0.453712, â€¦ 0.475159]</td><td>[2, 5, â€¦ 3]</td></tr><tr><td>513401</td><td>569008456</td><td>2023-06-01 05:09:38</td><td>[9778804, 9778219, â€¦ 9778939]</td><td>[9790784]</td><td>[9484153, 9790825, â€¦ 9527795]</td><td>[0, 0, â€¦ 0]</td><td>[0.393523, 0.518457, â€¦ 0.357469]</td><td>[8, 1, â€¦ 11]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ user_id â”† impression â”† impressio â”† article_i â”† â€¦ â”† article_i â”† labels    â”† scores    â”† ranked_sc â”‚\n",
       "â”‚ ---     â”† _id        â”† n_time    â”† d_fixed   â”†   â”† ds_inview â”† ---       â”† ---       â”† ores      â”‚\n",
       "â”‚ u32     â”† ---        â”† ---       â”† ---       â”†   â”† ---       â”† list[i8]  â”† list[f64] â”† ---       â”‚\n",
       "â”‚         â”† u32        â”† datetime[ â”† list[i32] â”†   â”† list[i32] â”†           â”†           â”† list[i64] â”‚\n",
       "â”‚         â”†            â”† Î¼s]       â”†           â”†   â”†           â”†           â”†           â”†           â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 983098  â”† 202907971  â”† 2023-05-2 â”† [9775701, â”† â€¦ â”† [9785349, â”† [0, 0, â€¦  â”† [0.479354 â”† [2, 5, â€¦  â”‚\n",
       "â”‚         â”†            â”† 8         â”† 9775983,  â”†   â”† 9785209,  â”† 0]        â”† ,         â”† 3]        â”‚\n",
       "â”‚         â”†            â”† 20:43:01  â”† â€¦         â”†   â”† â€¦         â”†           â”† 0.453712, â”†           â”‚\n",
       "â”‚         â”†            â”†           â”† 9778939]  â”†   â”† 9780736]  â”†           â”† â€¦         â”†           â”‚\n",
       "â”‚         â”†            â”†           â”†           â”†   â”†           â”†           â”† 0.475159] â”†           â”‚\n",
       "â”‚ 513401  â”† 569008456  â”† 2023-06-0 â”† [9778804, â”† â€¦ â”† [9484153, â”† [0, 0, â€¦  â”† [0.393523 â”† [8, 1, â€¦  â”‚\n",
       "â”‚         â”†            â”† 1         â”† 9778219,  â”†   â”† 9790825,  â”† 0]        â”† ,         â”† 11]       â”‚\n",
       "â”‚         â”†            â”† 05:09:38  â”† â€¦         â”†   â”† â€¦         â”†           â”† 0.518457, â”†           â”‚\n",
       "â”‚         â”†            â”†           â”† 9778939]  â”†   â”† 9527795]  â”†           â”† â€¦         â”†           â”‚\n",
       "â”‚         â”†            â”†           â”†           â”†   â”†           â”†           â”† 0.357469] â”†           â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.with_columns(\n",
    "    pl.col(\"scores\")\n",
    "    .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "    .alias(\"ranked_scores\")\n",
    ")\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using the validation, simply add the testset to your flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2446it [00:00, 22910.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping ebnerd_predictions/predictions.txt to ebnerd_predictions/smoolasfk_predictions-NRMS.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_submission_file(\n",
    "    impression_ids=df_test[DEFAULT_IMPRESSION_ID_COL],\n",
    "    prediction_scores=df_test[\"ranked_scores\"],\n",
    "    path=DUMP_DIR.joinpath(\"predictions.txt\"),\n",
    "    filename_zip=f\"smoolasfk_predictions-{MODEL_NAME}.zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>read_time</th>\n",
       "      <th>scroll_percentage</th>\n",
       "      <th>device_type</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_sso_user</th>\n",
       "      <th>gender</th>\n",
       "      <th>postcode</th>\n",
       "      <th>age</th>\n",
       "      <th>is_subscriber</th>\n",
       "      <th>session_id</th>\n",
       "      <th>next_read_time</th>\n",
       "      <th>next_scroll_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-28 04:21:24</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9783865, 9784591, 9784679, 9784696, 9784710]</td>\n",
       "      <td>[9784696]</td>\n",
       "      <td>22548</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>142</td>\n",
       "      <td>72.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-28 04:31:48</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9782884, 9783865, 9782726, 9695098, 9782806, ...</td>\n",
       "      <td>[9784281]</td>\n",
       "      <td>22548</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>143</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impression_id  article_id     impression_time  read_time  \\\n",
       "0          96791         NaN 2023-05-28 04:21:24        9.0   \n",
       "1          96798         NaN 2023-05-28 04:31:48       46.0   \n",
       "\n",
       "   scroll_percentage  device_type  \\\n",
       "0                NaN            2   \n",
       "1                NaN            2   \n",
       "\n",
       "                                  article_ids_inview article_ids_clicked  \\\n",
       "0      [9783865, 9784591, 9784679, 9784696, 9784710]           [9784696]   \n",
       "1  [9782884, 9783865, 9782726, 9695098, 9782806, ...           [9784281]   \n",
       "\n",
       "   user_id  is_sso_user  gender  postcode  age  is_subscriber  session_id  \\\n",
       "0    22548        False     NaN       NaN  NaN          False         142   \n",
       "1    22548        False     NaN       NaN  NaN          False         143   \n",
       "\n",
       "   next_read_time  next_scroll_percentage  \n",
       "0            72.0                   100.0  \n",
       "1            16.0                    28.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the parquet file\n",
    "file_path = '/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/ebnerd_small/validation/behaviors.parquet'\n",
    "# Load the parquet file\n",
    "df = pd.read_parquet(file_path)\n",
    "df.head(2)\n",
    "# # Look for the specified Impression IDs\n",
    "# impression_ids = [202907971, 6451339]\n",
    "# filtered_data = df[df['impression_id'].isin(impression_ids)]\n",
    "# filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>read_time</th>\n",
       "      <th>scroll_percentage</th>\n",
       "      <th>device_type</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_sso_user</th>\n",
       "      <th>gender</th>\n",
       "      <th>postcode</th>\n",
       "      <th>age</th>\n",
       "      <th>is_subscriber</th>\n",
       "      <th>session_id</th>\n",
       "      <th>is_beyond_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6451339</td>\n",
       "      <td>2023-06-05 15:02:49</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9796527, 7851321, 9798805, 9795150, 9531110, ...</td>\n",
       "      <td>35982</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>388</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6451363</td>\n",
       "      <td>2023-06-05 15:03:56</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9798532, 9791602, 9798975, 9791334, 9793856, ...</td>\n",
       "      <td>36012</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>804</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impression_id     impression_time  read_time  scroll_percentage  \\\n",
       "0        6451339 2023-06-05 15:02:49        8.0                NaN   \n",
       "1        6451363 2023-06-05 15:03:56       20.0                NaN   \n",
       "\n",
       "   device_type                                 article_ids_inview  user_id  \\\n",
       "0            2  [9796527, 7851321, 9798805, 9795150, 9531110, ...    35982   \n",
       "1            2  [9798532, 9791602, 9798975, 9791334, 9793856, ...    36012   \n",
       "\n",
       "   is_sso_user  gender  postcode  age  is_subscriber  session_id  \\\n",
       "0        False     NaN       NaN  NaN          False         388   \n",
       "1        False     NaN       NaN  NaN          False         804   \n",
       "\n",
       "   is_beyond_accuracy  \n",
       "0               False  \n",
       "1               False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/ebnerd_testset/test/behaviors.parquet'\n",
    "# Load the parquet file\n",
    "df = pd.read_parquet(file_path)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
