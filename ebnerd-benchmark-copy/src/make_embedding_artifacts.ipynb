{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make article embeddings using Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from ebrec.utils._nlp import generate_embeddings_with_transformers\n",
    "from ebrec.utils._python import batch_items_generator\n",
    "from ebrec.utils._polars import concat_str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path for loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings will be stored at: /dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/artifacts/FacebookAI_xlm-roberta-large\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data\").expanduser()\n",
    "DUMP_DIR = DATA_PATH.joinpath(\"artifacts\", TRANSFORMER_MODEL_NAME.replace(\"/\", \"_\"))\n",
    "DUMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Embeddings will be stored at: {DUMP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[Î¼s]</td><td>bool</td><td>str</td><td>datetime[Î¼s]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3000022</td><td>&quot;Hanks beskyldtâ€¦</td><td>&quot;Tom Hanks har â€¦</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;Tom Hanks skulâ€¦</td><td>2006-09-20 09:24:18</td><td>[3518381]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[&quot;David Gardner&quot;]</td><td>[&quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, â€¦ &quot;Litteratur&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9911</td><td>&quot;Negative&quot;</td></tr><tr><td>3000063</td><td>&quot;Bostrups aske â€¦</td><td>&quot;StudievÃ¦rten bâ€¦</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;StrÃ¥lende sensâ€¦</td><td>2006-09-24 07:45:30</td><td>[3170935, 3170939]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, â€¦ &quot;Personlig begivenhed&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.5155</td><td>&quot;Neutral&quot;</td></tr><tr><td>3000613</td><td>&quot;Jesper Olsen râ€¦</td><td>&quot;Den tidligere â€¦</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Jesper Olsen, â€¦</td><td>2006-05-09 11:29:00</td><td>[3164998]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[&quot;Frankrig&quot;, &quot;Jesper Olsen&quot;, â€¦ &quot;Jesper Olsen&quot;]</td><td>[&quot;LOC&quot;, &quot;PER&quot;, â€¦ &quot;PER&quot;]</td><td>[&quot;Kendt&quot;, &quot;Sport&quot;, â€¦ &quot;Sygdom og behandling&quot;]</td><td>142</td><td>[196, 271]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9876</td><td>&quot;Negative&quot;</td></tr><tr><td>3000700</td><td>&quot;Madonna toplÃ¸sâ€¦</td><td>&quot;47-Ã¥rige Madonâ€¦</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Skal du have sâ€¦</td><td>2006-05-04 11:03:12</td><td>[3172046]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Livsstil&quot;, &quot;Underholdning&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8786</td><td>&quot;Neutral&quot;</td></tr><tr><td>3000840</td><td>&quot;Otto Brandenbuâ€¦</td><td>&quot;Sangeren og skâ€¦</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;&#x27;Og lidt for Sâ€¦</td><td>2007-03-01 18:34:00</td><td>[3914446]</td><td>&quot;article_defaulâ€¦</td><td>&quot;https://ekstraâ€¦</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, â€¦ &quot;Musik og lyd&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9468</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ article_i â”† title     â”† subtitle  â”† last_modi â”† â€¦ â”† total_pag â”† total_rea â”† sentiment â”† sentimen â”‚\n",
       "â”‚ d         â”† ---       â”† ---       â”† fied_time â”†   â”† eviews    â”† d_time    â”† _score    â”† t_label  â”‚\n",
       "â”‚ ---       â”† str       â”† str       â”† ---       â”†   â”† ---       â”† ---       â”† ---       â”† ---      â”‚\n",
       "â”‚ i32       â”†           â”†           â”† datetime[ â”†   â”† i32       â”† f32       â”† f32       â”† str      â”‚\n",
       "â”‚           â”†           â”†           â”† Î¼s]       â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 3000022   â”† Hanks     â”† Tom Hanks â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.9911    â”† Negative â”‚\n",
       "â”‚           â”† beskyldt  â”† har angiv â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† for misha â”† eligt     â”† 06:20:32  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† ndling    â”† mishandâ€¦  â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 3000063   â”† Bostrups  â”† StudievÃ¦r â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.5155    â”† Neutral  â”‚\n",
       "â”‚           â”† aske      â”† ten blev  â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† spredt i  â”† mindet    â”† 06:20:32  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† FuresÃ¸en  â”† med glaâ€¦  â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 3000613   â”† Jesper    â”† Den       â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.9876    â”† Negative â”‚\n",
       "â”‚           â”† Olsen     â”† tidligere â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† ramt af   â”† danske    â”† 06:20:33  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† hjerneblÃ¸ â”† landshold â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† dnâ€¦       â”† ssâ€¦       â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 3000700   â”† Madonna   â”† 47-Ã¥rige  â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.8786    â”† Neutral  â”‚\n",
       "â”‚           â”† toplÃ¸s    â”† Madonna   â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† med heste â”† poserer   â”† 06:20:33  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”† bÃ¥de toâ€¦  â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 3000840   â”† Otto Bran â”† Sangeren  â”† 2023-06-2 â”† â€¦ â”† null      â”† null      â”† 0.9468    â”† Negative â”‚\n",
       "â”‚           â”† denburg   â”† og skuesp â”† 9         â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”† er dÃ¸d    â”† illeren   â”† 06:20:33  â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚           â”†           â”† Otto Bâ€¦   â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## REMEMBER CHANGE DATA PATH IF USING LARGE!\n",
    "\n",
    "df_articles = pl.read_parquet(DATA_PATH.joinpath(\"ebnerd_small/articles.parquet\"))\n",
    "df_articles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just going to demo, set to False to run all articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO = False #True\n",
    "if DEMO:\n",
    "    df_articles = df_articles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_columns = [\"title\", \"subtitle\", \"body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the Transformer model and the batch-size of which it will iterate the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the column with text data you want to embed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>title-subtitle-body</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Hanks beskyldtâ€¦</td></tr><tr><td>&quot;Bostrups aske â€¦</td></tr><tr><td>&quot;Jesper Olsen râ€¦</td></tr><tr><td>&quot;Madonna toplÃ¸sâ€¦</td></tr><tr><td>&quot;Otto Brandenbuâ€¦</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ title-subtitle-body               â”‚\n",
       "â”‚ ---                               â”‚\n",
       "â”‚ str                               â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ Hanks beskyldt for mishandling Tâ€¦ â”‚\n",
       "â”‚ Bostrups aske spredt i FuresÃ¸en â€¦ â”‚\n",
       "â”‚ Jesper Olsen ramt af hjerneblÃ¸dnâ€¦ â”‚\n",
       "â”‚ Madonna toplÃ¸s med heste 47-Ã¥rigâ€¦ â”‚\n",
       "â”‚ Otto Brandenburg er dÃ¸d Sangerenâ€¦ â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles, col_name = concat_str_columns(df_articles, concat_columns)\n",
    "\n",
    "df_articles.select(col_name).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding:   0%|          | 0/1962 [00:00<?, ?text/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding:   0%|          | 3/1962 [00:06<1:01:27,  1.88s/text]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m      4\u001b[0m chunked_text_list \u001b[38;5;241m=\u001b[39m batch_items_generator(df_articles[col_name]\u001b[38;5;241m.\u001b[39mto_list(), BATCH_SIZE)\n\u001b[1;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m     generate_embeddings_with_transformers( \u001b[38;5;66;03m#Passes batched texted to tranformer \u001b[39;00m\n\u001b[1;32m      7\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#Stacks the embeddings into a single tensor\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m n_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(df_articles\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m/\u001b[39m BATCH_SIZE))\n\u001b[1;32m      4\u001b[0m chunked_text_list \u001b[38;5;241m=\u001b[39m batch_items_generator(df_articles[col_name]\u001b[38;5;241m.\u001b[39mto_list(), BATCH_SIZE)\n\u001b[1;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mgenerate_embeddings_with_transformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#Passes batched texted to tranformer \u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text_list \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m     14\u001b[0m         chunked_text_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mn_batches, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mlist\u001b[39m(embeddings)) \u001b[38;5;66;03m#Stacks the embeddings into a single tensor\u001b[39;00m\n",
      "File \u001b[0;32m/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/src/ebrec/utils/_nlp.py:83\u001b[0m, in \u001b[0;36mgenerate_embeddings_with_transformers\u001b[0;34m(model, tokenizer, text_list, batch_size, device, disable_tqdm)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm):\n\u001b[0;32m---> 83\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     84\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[1;32m     86\u001b[0m             output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m         )\n\u001b[1;32m     88\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/src/ebrec/utils/_nlp.py:83\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm):\n\u001b[0;32m---> 83\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m {feat: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m feat, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(feature_names, batch)}\n\u001b[1;32m     84\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[1;32m     86\u001b[0m             output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m         )\n\u001b[1;32m     88\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32*2\n",
    "n_batches = int(np.ceil(df_articles.height / BATCH_SIZE))\n",
    "\n",
    "chunked_text_list = batch_items_generator(df_articles[col_name].to_list(), BATCH_SIZE)\n",
    "embeddings = (\n",
    "    generate_embeddings_with_transformers( #Passes batched texted to tranformer \n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        text_list=text_list,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "    for text_list in tqdm(\n",
    "        chunked_text_list, desc=\"Encoding\", total=n_batches, unit=\"text\"\n",
    "    )\n",
    ")\n",
    "embeddings = torch.vstack(list(embeddings)) #Stacks the embeddings into a single tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_name = f\"{col_name}-{TRANSFORMER_MODEL_NAME}\"\n",
    "series_emb = pl.Series(embeddings_name, embeddings.to(\"cpu\").numpy())\n",
    "df_emb = df_articles.select(\"article_id\").with_columns(series_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to: /dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/artifacts/FacebookAI_xlm-roberta-large/title-subtitle-body-FacebookAI_xlm-roberta-large.parquet\n"
     ]
    }
   ],
   "source": [
    "file_path = DUMP_DIR.joinpath(f\"{embeddings_name.replace('/', '_')}.parquet\")\n",
    "df_emb.write_parquet(file_path)\n",
    "print(f\"Embeddings saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
