{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make article embeddings using Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from ebrec.utils._nlp import generate_embeddings_with_transformers\n",
    "from ebrec.utils._python import batch_items_generator\n",
    "from ebrec.utils._polars import concat_str_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path for loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings will be stored at: /dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/artifacts/FacebookAI_xlm-roberta-large\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(\"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data\").expanduser()\n",
    "DUMP_DIR = DATA_PATH.joinpath(\"artifacts\", TRANSFORMER_MODEL_NAME.replace(\"/\", \"_\"))\n",
    "DUMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Embeddings will be stored at: {DUMP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3000022</td><td>&quot;Hanks beskyldt…</td><td>&quot;Tom Hanks har …</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;Tom Hanks skul…</td><td>2006-09-20 09:24:18</td><td>[3518381]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;David Gardner&quot;]</td><td>[&quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Litteratur&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9911</td><td>&quot;Negative&quot;</td></tr><tr><td>3000063</td><td>&quot;Bostrups aske …</td><td>&quot;Studieværten b…</td><td>2023-06-29 06:20:32</td><td>false</td><td>&quot;Strålende sens…</td><td>2006-09-24 07:45:30</td><td>[3170935, 3170939]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, … &quot;Personlig begivenhed&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.5155</td><td>&quot;Neutral&quot;</td></tr><tr><td>3000613</td><td>&quot;Jesper Olsen r…</td><td>&quot;Den tidligere …</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Jesper Olsen, …</td><td>2006-05-09 11:29:00</td><td>[3164998]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;Frankrig&quot;, &quot;Jesper Olsen&quot;, … &quot;Jesper Olsen&quot;]</td><td>[&quot;LOC&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kendt&quot;, &quot;Sport&quot;, … &quot;Sygdom og behandling&quot;]</td><td>142</td><td>[196, 271]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9876</td><td>&quot;Negative&quot;</td></tr><tr><td>3000700</td><td>&quot;Madonna topløs…</td><td>&quot;47-årige Madon…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Skal du have s…</td><td>2006-05-04 11:03:12</td><td>[3172046]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Livsstil&quot;, &quot;Underholdning&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8786</td><td>&quot;Neutral&quot;</td></tr><tr><td>3000840</td><td>&quot;Otto Brandenbu…</td><td>&quot;Sangeren og sk…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;&#x27;Og lidt for S…</td><td>2007-03-01 18:34:00</td><td>[3914446]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Underholdning&quot;, … &quot;Musik og lyd&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9468</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3000022   ┆ Hanks     ┆ Tom Hanks ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9911    ┆ Negative │\n",
       "│           ┆ beskyldt  ┆ har angiv ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ for misha ┆ eligt     ┆ 06:20:32  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ ndling    ┆ mishand…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3000063   ┆ Bostrups  ┆ Studievær ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.5155    ┆ Neutral  │\n",
       "│           ┆ aske      ┆ ten blev  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ spredt i  ┆ mindet    ┆ 06:20:32  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Furesøen  ┆ med gla…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3000613   ┆ Jesper    ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9876    ┆ Negative │\n",
       "│           ┆ Olsen     ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ ramt af   ┆ danske    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ hjerneblø ┆ landshold ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ dn…       ┆ ss…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3000700   ┆ Madonna   ┆ 47-årige  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8786    ┆ Neutral  │\n",
       "│           ┆ topløs    ┆ Madonna   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ med heste ┆ poserer   ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ både to…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3000840   ┆ Otto Bran ┆ Sangeren  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9468    ┆ Negative │\n",
       "│           ┆ denburg   ┆ og skuesp ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er død    ┆ illeren   ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ Otto B…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## REMEMBER CHANGE DATA PATH IF USING LARGE!\n",
    "\n",
    "df_articles = pl.read_parquet(DATA_PATH.joinpath(\"ebnerd_small/articles.parquet\"))\n",
    "df_articles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just going to demo, set to False to run all articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO = False #True\n",
    "if DEMO:\n",
    "    df_articles = df_articles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_columns = [\"title\", \"subtitle\", \"body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the Transformer model and the batch-size of which it will iterate the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the column with text data you want to embed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>title-subtitle-body</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Hanks beskyldt…</td></tr><tr><td>&quot;Bostrups aske …</td></tr><tr><td>&quot;Jesper Olsen r…</td></tr><tr><td>&quot;Madonna topløs…</td></tr><tr><td>&quot;Otto Brandenbu…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌───────────────────────────────────┐\n",
       "│ title-subtitle-body               │\n",
       "│ ---                               │\n",
       "│ str                               │\n",
       "╞═══════════════════════════════════╡\n",
       "│ Hanks beskyldt for mishandling T… │\n",
       "│ Bostrups aske spredt i Furesøen … │\n",
       "│ Jesper Olsen ramt af hjerneblødn… │\n",
       "│ Madonna topløs med heste 47-årig… │\n",
       "│ Otto Brandenburg er død Sangeren… │\n",
       "└───────────────────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles, col_name = concat_str_columns(df_articles, concat_columns)\n",
    "\n",
    "df_articles.select(col_name).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding:   0%|          | 0/1962 [00:00<?, ?text/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding:   0%|          | 3/1962 [00:06<1:01:27,  1.88s/text]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m      4\u001b[0m chunked_text_list \u001b[38;5;241m=\u001b[39m batch_items_generator(df_articles[col_name]\u001b[38;5;241m.\u001b[39mto_list(), BATCH_SIZE)\n\u001b[1;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m     generate_embeddings_with_transformers( \u001b[38;5;66;03m#Passes batched texted to tranformer \u001b[39;00m\n\u001b[1;32m      7\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#Stacks the embeddings into a single tensor\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m n_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(df_articles\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m/\u001b[39m BATCH_SIZE))\n\u001b[1;32m      4\u001b[0m chunked_text_list \u001b[38;5;241m=\u001b[39m batch_items_generator(df_articles[col_name]\u001b[38;5;241m.\u001b[39mto_list(), BATCH_SIZE)\n\u001b[1;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mgenerate_embeddings_with_transformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#Passes batched texted to tranformer \u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text_list \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m     14\u001b[0m         chunked_text_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mn_batches, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mlist\u001b[39m(embeddings)) \u001b[38;5;66;03m#Stacks the embeddings into a single tensor\u001b[39;00m\n",
      "File \u001b[0;32m/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/src/ebrec/utils/_nlp.py:83\u001b[0m, in \u001b[0;36mgenerate_embeddings_with_transformers\u001b[0;34m(model, tokenizer, text_list, batch_size, device, disable_tqdm)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm):\n\u001b[0;32m---> 83\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     84\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[1;32m     86\u001b[0m             output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m         )\n\u001b[1;32m     88\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/src/ebrec/utils/_nlp.py:83\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm):\n\u001b[0;32m---> 83\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m {feat: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m feat, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(feature_names, batch)}\n\u001b[1;32m     84\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[1;32m     86\u001b[0m             output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m         )\n\u001b[1;32m     88\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32*2\n",
    "n_batches = int(np.ceil(df_articles.height / BATCH_SIZE))\n",
    "\n",
    "chunked_text_list = batch_items_generator(df_articles[col_name].to_list(), BATCH_SIZE)\n",
    "embeddings = (\n",
    "    generate_embeddings_with_transformers( #Passes batched texted to tranformer \n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        text_list=text_list,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "    for text_list in tqdm(\n",
    "        chunked_text_list, desc=\"Encoding\", total=n_batches, unit=\"text\"\n",
    "    )\n",
    ")\n",
    "embeddings = torch.vstack(list(embeddings)) #Stacks the embeddings into a single tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_name = f\"{col_name}-{TRANSFORMER_MODEL_NAME}\"\n",
    "series_emb = pl.Series(embeddings_name, embeddings.to(\"cpu\").numpy())\n",
    "df_emb = df_articles.select(\"article_id\").with_columns(series_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to: /dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/artifacts/FacebookAI_xlm-roberta-large/title-subtitle-body-FacebookAI_xlm-roberta-large.parquet\n"
     ]
    }
   ],
   "source": [
    "file_path = DUMP_DIR.joinpath(f\"{embeddings_name.replace('/', '_')}.parquet\")\n",
    "df_emb.write_parquet(file_path)\n",
    "print(f\"Embeddings saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
