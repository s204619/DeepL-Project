{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dtu/blackhole/14/155764/DeepL-Project-Corn2/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Directly set the values from args_nrms.py\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "import polars as pl\n",
    "import shutil\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from ebrec.utils2._constants import *\n",
    "\n",
    "from ebrec.utils2._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    "    ebnerd_from_path,\n",
    ")\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "\n",
    "from ebrec.utils2._python import (\n",
    "    write_submission_file,\n",
    "    rank_predictions_by_score,\n",
    "    write_json_file,\n",
    ")\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._polars import split_df_chunks, concat_str_columns\n",
    "\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader, NRMSDataLoaderPretransform\n",
    "from ebrec.models.newsrec.model_config2 import (\n",
    "    hparams_nrms,\n",
    "    hparams_nrms_docvec,\n",
    "    hparams_to_dict,\n",
    "    print_hparams,\n",
    ")\n",
    "from ebrec.models.newsrec.nrms_docvec2 import NRMSDocVec\n",
    "from ebrec.models.newsrec import NRMSModel\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Constants\n",
    "SEED = 42  # Replace with the actual seed value if different\n",
    "DATASPLIT = \"ebnerd_small\"\n",
    "DEBUG = False  # Set to True if you want to enable debug mode\n",
    "BS_TRAIN = 64 #batch i dataload\n",
    "BS_TEST = 32 #val\n",
    "BATCH_SIZE_TEST_WO_B = 32\n",
    "BATCH_SIZE_TEST_W_B = 16\n",
    "HISTORY_SIZE = 10\n",
    "NPRATIO = 4\n",
    "EPOCHS = 1\n",
    "TRAIN_FRACTION = 1 # if not DEBUG else 0.0001\n",
    "FRACTION_TEST = 1# if not DEBUG else 0.0001\n",
    "\n",
    "# Example usage in your code\n",
    "# PATH = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))  # Replace with actual data path\n",
    "PATH = Path(\"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data\").expanduser()\n",
    "DATASPLIT = \"ebnerd_small\" # TODO if change to change make_embedding_artifacts.ipynb file (embeddings)\n",
    "\n",
    "# Access arguments as variables\n",
    "# SEED = args.seed\n",
    "# DATASPLIT = args.datasplit\n",
    "# DEBUG = args.debug\n",
    "# BS_TRAIN = args.bs_train\n",
    "# BS_TEST = args.bs_test\n",
    "# BATCH_SIZE_TEST_WO_B = args.batch_size_test_wo_b\n",
    "# BATCH_SIZE_TEST_W_B = args.batch_size_test_w_b\n",
    "# HISTORY_SIZE = args.history_size\n",
    "# NPRATIO = args.npratio\n",
    "# EPOCHS = args.epochs\n",
    "# TRAIN_FRACTION = args.train_fraction if not DEBUG else 0.0001\n",
    "# FRACTION_TEST = 0.0001  # args.fraction_test if not DEBUG else 0.0001\n",
    "\n",
    "# The rest of your code remains the same\n",
    "NRMSLoader_training = (\n",
    "    NRMSDataLoaderPretransform\n",
    "    if \"NRMSDataLoaderPretransform\" == \"NRMSDataLoaderPretransform\"\n",
    "    else NRMSDataLoader\n",
    ")\n",
    "\n",
    "# =====================================================================================\n",
    "#  ############################# UNIQUE FOR NRMSModel ################################\n",
    "# =====================================================================================\n",
    "\n",
    "# Model in use:\n",
    "model_func = NRMSModel\n",
    "hparams = hparams_nrms\n",
    "\n",
    "## NRMSModel:\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_TITLE_COL, DEFAULT_SUBTITLE_COL, DEFAULT_BODY_COL]\n",
    "\n",
    "TRANSFORMER_MODEL_NAME = \"Maltehb/danish-bert-botxo\"  # Replace with actual transformer model name\n",
    "MAX_TITLE_LENGTH = 30  # Replace with actual max title length\n",
    "hparams.title_size = MAX_TITLE_LENGTH\n",
    "hparams.history_size = HISTORY_SIZE\n",
    "hparams.head_num = 8  # Replace with actual head number\n",
    "hparams.head_dim = 64  # Replace with actual head dimension\n",
    "hparams.attention_hidden_dim = 200  # Replace with actual attention hidden dimension\n",
    "hparams.optimizer = \"adam\"  # Replace with actual optimizer\n",
    "hparams.loss = \"categorical_crossentropy\"  # Replace with actual loss\n",
    "hparams.dropout = 0.2  # Replace with actual dropout rate\n",
    "hparams.learning_rate = 0.001  # Replace with actual learning rate\n",
    "\n",
    "# =============\n",
    "print(\"Initiating articles...\")\n",
    "df_articles = pl.read_parquet(\"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/ebnerd_small/articles.parquet\")\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_size: 30\n",
      "history_size: 10\n",
      "head_num: 8\n",
      "head_dim: 64\n",
      "attention_hidden_dim: 200\n",
      "optimizer: adam\n",
      "loss: categorical_crossentropy\n",
      "dropout: 0.2\n",
      "learning_rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================================================\n",
    "#  ############################# UNIQUE FOR NRMSDocVec ###############################\n",
    "# =====================================================================================\n",
    "\n",
    "print_hparams(hparams)\n",
    "\n",
    "# Dump paths:\n",
    "DUMP_DIR = Path(\"ebnerd_predictions\")\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)\n",
    "#\n",
    "DT_NOW = dt.datetime.now()\n",
    "#\n",
    "MODEL_NAME = model_func.__name__\n",
    "MODEL_OUTPUT_NAME = f\"{MODEL_NAME}-{DT_NOW}\"\n",
    "#\n",
    "ARTIFACT_DIR = DUMP_DIR.joinpath(\"test_predictions\", MODEL_OUTPUT_NAME)\n",
    "# Model monitoring:\n",
    "MODEL_WEIGHTS = DUMP_DIR.joinpath(f\"state_dict/{MODEL_OUTPUT_NAME}/weights\")\n",
    "LOG_DIR = DUMP_DIR.joinpath(f\"runs/{MODEL_OUTPUT_NAME}\")\n",
    "# Evaluating the test test can be memory intensive, we'll chunk it up:\n",
    "TEST_CHUNKS_DIR = ARTIFACT_DIR.joinpath(\"test_chunks\")\n",
    "TEST_CHUNKS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "N_CHUNKS_TEST = 10  # Replace with actual number of test chunks\n",
    "CHUNKS_DONE = 0  # Replace with actual number of chunks already processed\n",
    "# Just trying keeping the dataframe slime:\n",
    "COLUMNS = [\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "]\n",
    "# # Store hparams\n",
    "# write_json_file(\n",
    "#     hparams_to_dict(hparams),\n",
    "#     ARTIFACT_DIR.joinpath(f\"{MODEL_NAME}_hparams.json\"),\n",
    "# )\n",
    "# write_json_file(vars(args), ARTIFACT_DIR.joinpath(f\"{MODEL_NAME}_argparser.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating training-dataloader\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================================================\n",
    "# We'll use the training + validation sets for training.\n",
    "df = (\n",
    "    pl.concat(\n",
    "        [\n",
    "            ebnerd_from_path(\n",
    "                PATH.joinpath(DATASPLIT, \"train\"),\n",
    "                history_size=HISTORY_SIZE,\n",
    "                padding=0,\n",
    "            ),\n",
    "            ebnerd_from_path(\n",
    "                PATH.joinpath(DATASPLIT, \"validation\"),\n",
    "                history_size=HISTORY_SIZE,\n",
    "                padding=0,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    .sample(fraction=TRAIN_FRACTION, shuffle=True, seed=SEED)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=NPRATIO,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    ")\n",
    "\n",
    "# We keep the last day of our training data as the validation set.\n",
    "last_dt = df[DEFAULT_IMPRESSION_TIMESTAMP_COL].dt.date().max() - dt.timedelta(days=1)\n",
    "df_train = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL).dt.date() < last_dt)\n",
    "df_validation = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL).dt.date() >= last_dt)\n",
    "\n",
    "# =====================================================================================\n",
    "print(f\"Initiating training-dataloader\")\n",
    "train_dataloader = NRMSLoader_training(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BS_TRAIN,\n",
    ")\n",
    "\n",
    "val_dataloader = NRMSLoader_training(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=BS_TRAIN,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [Train]:  21%|██▏       | 3/14 [00:00<00:00, 27.26it/s, loss=0.5888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [Train]: 100%|██████████| 14/14 [00:00<00:00, 37.97it/s, loss=0.5369]\n",
      "Epoch 1/1 [Valid]: 100%|██████████| 2/2 [00:00<00:00, 172.73it/s, loss=0.0717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.5369, Val Loss: 0.5017\n",
      "\n",
      "Validation loss improved from inf to 0.50172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/src/ebrec/models/newsrec/nrmspy_1.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(filepath))\n",
      "Predicting: 100%|██████████| 2/2 [00:00<00:00, 177.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "# Original Model\n",
    "# _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "\n",
    "# Works fine -- Can change epochs on line 67\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from ebrec.models.newsrec import NRMSModel, NRMSWrapper\n",
    "\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "WEIGHTS_DIR = f\"downloads/data/state_dict/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = f\"{WEIGHTS_DIR}/weights.pt\"\n",
    "\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "# Create a custom ModelCheckpoint for PyTorch\n",
    "class PyTorchModelCheckpoint:\n",
    "    def __init__(self, filepath, model_wrapper=None, save_best_only=True, save_weights_only=True, verbose=1):\n",
    "        self.filepath = filepath\n",
    "        self.model_wrapper = model_wrapper  # Store the model wrapper reference\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.verbose = verbose\n",
    "        self.best_val_loss = float('inf')\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs.get('val_loss', None)\n",
    "        if val_loss is None:\n",
    "            return\n",
    "        \n",
    "        if self.save_best_only:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                if self.verbose:\n",
    "                    print(f'\\nValidation loss improved from {self.best_val_loss:.5f} to {val_loss:.5f}')\n",
    "                self.best_val_loss = val_loss\n",
    "                # Use the model_wrapper reference\n",
    "                self.model_wrapper.save_weights(self.filepath)\n",
    "        else:\n",
    "            self.model_wrapper.save_weights(self.filepath)\n",
    "\n",
    "# Initialize model first\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "\n",
    "# Best hyperparameters: {'head_num': 19, 'head_dim': 29, 'attention_hidden_dim': 145, 'dropout': 0.22088583494496855, 'learning_rate': 0.00030309205322750723}\n",
    "\n",
    "hparams_nrms.head_num = 19\n",
    "hparams_nrms.head_dim = 29\n",
    "hparams_nrms.attention_hidden_dim = 145\n",
    "hparams_nrms.dropout = 0.22088583494496855\n",
    "hparams_nrms.learning_rate = 0.00030309205322750723\n",
    "\n",
    "pytorch_model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "model = NRMSWrapper(pytorch_model)\n",
    "\n",
    "# Then create the callback with the model reference\n",
    "modelcheckpoint = PyTorchModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS,\n",
    "    model_wrapper=model,  # Pass the model wrapper\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Training\n",
    "hist = model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=4, ### EPOCHS INPUT\n",
    "    callbacks=[modelcheckpoint]\n",
    ")\n",
    "\n",
    "# Load weights using the wrapper\n",
    "model.load_weights(filepath=MODEL_WEIGHTS)\n",
    "\n",
    "# Get predictions\n",
    "pred_validation = model.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating testset...\n",
      "Initiating testset without beyond-accuracy...\n",
      "Test chunk: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 5/5 [00:00<00:00, 16.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating testset with beyond-accuracy...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================================================\n",
    "print(\"Initiating testset...\")\n",
    "df_test = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(\"ebnerd_testset\", \"test\"),\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding=0,\n",
    "    )\n",
    "    .sample(fraction=FRACTION_TEST)\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "        .list.first()\n",
    "        .alias(DEFAULT_CLICKED_ARTICLES_COL)\n",
    "    )\n",
    "    .select(COLUMNS + [DEFAULT_IS_BEYOND_ACCURACY_COL])\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "        .list.eval(pl.element() * 0)\n",
    "        .alias(DEFAULT_LABELS_COL)\n",
    "    )\n",
    ")\n",
    "# Split test in beyond-accuracy TRUE / FALSE. In the BA 'article_ids_inview' is 250.\n",
    "df_test_wo_beyond = df_test.filter(~pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "df_test_w_beyond = df_test.filter(pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "\n",
    "df_test_chunks = split_df_chunks(df_test_wo_beyond, n_chunks=N_CHUNKS_TEST)\n",
    "df_pred_test_wo_beyond = []\n",
    "print(\"Initiating testset without beyond-accuracy...\")\n",
    "for i, df_test_chunk in enumerate(df_test_chunks[CHUNKS_DONE:], start=1 + CHUNKS_DONE):\n",
    "    print(f\"Test chunk: {i}/{len(df_test_chunks)}\")\n",
    "    # Initialize DataLoader\n",
    "    test_dataloader_wo_b = NRMSDataLoader(\n",
    "        behaviors=df_test_chunk,\n",
    "        article_dict=article_mapping,\n",
    "        unknown_representation=\"zeros\",\n",
    "        history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "        eval_mode=True,\n",
    "        batch_size=BATCH_SIZE_TEST_WO_B,\n",
    "    )\n",
    "    # Predict and clear session\n",
    "    scores = model.scorer.predict(test_dataloader_wo_b)\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Process the predictions\n",
    "    df_test_chunk = add_prediction_scores(df_test_chunk, scores.tolist()).with_columns(\n",
    "        pl.col(\"scores\")\n",
    "        .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "        .alias(\"ranked_scores\")\n",
    "    )\n",
    "\n",
    "    # Save the processed chunk\n",
    "    df_test_chunk.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "        TEST_CHUNKS_DIR.joinpath(f\"pred_wo_ba_{i}.parquet\")\n",
    "    )\n",
    "\n",
    "    # Append and clean up\n",
    "    df_pred_test_wo_beyond.append(df_test_chunk)\n",
    "\n",
    "    # Cleanup\n",
    "    del df_test_chunk, test_dataloader_wo_b, scores\n",
    "    gc.collect()\n",
    "\n",
    "df_pred_test_wo_beyond = pl.concat(df_pred_test_wo_beyond)\n",
    "df_pred_test_wo_beyond.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "    TEST_CHUNKS_DIR.joinpath(\"pred_wo_ba.parquet\")\n",
    ")\n",
    "# =====================================================================================\n",
    "print(\"Initiating testset with beyond-accuracy...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 6/6 [00:00<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prediction results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1353it [00:00, 30086.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping ebnerd_predictions/test_predictions/NRMSModel-2024-12-20 10:02:24.556055/predictions.txt to ebnerd_predictions/test_predictions/NRMSModel-2024-12-20 10:02:24.556055/NRMS-42-ebnerd_small.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataloader_w_b = NRMSDataLoader(\n",
    "    behaviors=df_test_w_beyond,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=BATCH_SIZE_TEST_W_B,\n",
    ")\n",
    "scores = model.scorer.predict(test_dataloader_w_b)\n",
    "df_pred_test_w_beyond = add_prediction_scores(\n",
    "    df_test_w_beyond, scores.tolist()\n",
    ").with_columns(\n",
    "    pl.col(\"scores\")\n",
    "    .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "    .alias(\"ranked_scores\")\n",
    ")\n",
    "df_pred_test_w_beyond.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "    TEST_CHUNKS_DIR.joinpath(\"pred_w_ba.parquet\")\n",
    ")\n",
    "\n",
    "# =====================================================================================\n",
    "print(\"Saving prediction results...\")\n",
    "df_test = pl.concat([df_pred_test_wo_beyond, df_pred_test_w_beyond])\n",
    "df_test.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "    ARTIFACT_DIR.joinpath(\"test_predictions.parquet\")\n",
    ")\n",
    "\n",
    "if TEST_CHUNKS_DIR.exists() and TEST_CHUNKS_DIR.is_dir():\n",
    "    shutil.rmtree(TEST_CHUNKS_DIR)\n",
    "\n",
    "write_submission_file(\n",
    "    impression_ids=df_test[DEFAULT_IMPRESSION_ID_COL],\n",
    "    prediction_scores=df_test[\"ranked_scores\"],\n",
    "    path=ARTIFACT_DIR.joinpath(\"predictions.txt\"),\n",
    "    filename_zip=f\"JuleAnd.zip\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
