{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This note book run the model (with optimal hyperparameters) and finally creates a predictions.txt file that can be submitted to codabench\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#____————____————____————____————\n",
    "# Define the history size and fraction and EPOCHS\n",
    "# ____————____————____————____————\n",
    "HISTORY_SIZE = 20 #30\n",
    "FRACTION = 0.001 #Fraction af datasæt\n",
    "EPOCHS = 2 \n",
    "FRACTION_testset = 0.0001\n",
    "#____————____————____————____————"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_ARTICLE_ID_COL,\n",
    "    DEFAULT_HISTORY_SCROLL_PERCENTAGE_COL, #-------\n",
    "    DEFAULT_HISTORY_READ_TIME_COL #-------\n",
    ")\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel, NRMSWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Available devices: []\n",
      "____————____————____————____———\n",
      "HISTORY_SIZE: 20\n",
      "FRACTION: 0.1\n",
      "____————____————____————____———\n",
      "\n",
      "shape: (2, 7)\n",
      "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
      "│ user_id ┆ impression_i ┆ impression_t ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ labels      │\n",
      "│ ---     ┆ d            ┆ ime          ┆ ixed         ┆ clicked      ┆ inview       ┆ ---         │\n",
      "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
      "│         ┆ u32          ┆ datetime[μs] ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆             │\n",
      "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
      "│ 475419  ┆ 308292451    ┆ 2023-05-20   ┆ [9764422,    ┆ [9772355]    ┆ [9494434,    ┆ [0, 0, … 0] │\n",
      "│         ┆              ┆ 05:56:28     ┆ 9764822, …   ┆              ┆ 9773084, …   ┆             │\n",
      "│         ┆              ┆              ┆ 9759071]     ┆              ┆ 9514481]     ┆             │\n",
      "│ 136339  ┆ 125333288    ┆ 2023-05-23   ┆ [9768634,    ┆ [9776917]    ┆ [9776287,    ┆ [0, 0, … 0] │\n",
      "│         ┆              ┆ 07:07:39     ┆ 9767534, …   ┆              ┆ 9776882, …   ┆             │\n",
      "│         ┆              ┆              ┆ 9769828]     ┆              ┆ 9776882]     ┆             │\n",
      "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘\n",
      "shape: (2, 7)\n",
      "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
      "│ user_id ┆ impression_i ┆ impression_t ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ labels      │\n",
      "│ ---     ┆ d            ┆ ime          ┆ ixed         ┆ clicked      ┆ inview       ┆ ---         │\n",
      "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
      "│         ┆ u32          ┆ datetime[μs] ┆ list[i32]    ┆ list[i32]    ┆ list[i32]    ┆             │\n",
      "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
      "│ 185193  ┆ 324016247    ┆ 2023-05-26   ┆ [9775562,    ┆ [9781859]    ┆ [9277339,    ┆ [0, 1, … 0] │\n",
      "│         ┆              ┆ 06:18:41     ┆ 9775673, …   ┆              ┆ 9781859, …   ┆             │\n",
      "│         ┆              ┆              ┆ 9779777]     ┆              ┆ 9778168]     ┆             │\n",
      "│ 1300067 ┆ 78498445     ┆ 2023-05-31   ┆ [9777026,    ┆ [9783655]    ┆ [9781998,    ┆ [0, 0, … 0] │\n",
      "│         ┆              ┆ 18:12:20     ┆ 9777374, …   ┆              ┆ 9788045, …   ┆             │\n",
      "│         ┆              ┆              ┆ 9779564]     ┆              ┆ 9789922]     ┆             │\n",
      "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var i…</td><td>&quot;Politiet frygt…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den ø…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars …</td><td>&quot;Biografgængern…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har …</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natascha… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind for…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "# Setup and load everything\n",
    "#-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "\n",
    "print(\"Loading data\")\n",
    "\n",
    "# List all physical devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available devices:\", physical_devices)\n",
    "\n",
    "\n",
    "#-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "## Load dataset\n",
    "# #-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "# def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Load ebnerd - function\n",
    "#     \"\"\"\n",
    "#     df_history = (\n",
    "#         pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "#         # .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL,DEFAULT_HISTORY_IMPRESSION_TIMESTAMP_COL)\n",
    "#         .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL,DEFAULT_HISTORY_IMPRESSION_TIMESTAMP_COL,DEFAULT_HISTORY_SCROLL_PERCENTAGE_COL,DEFAULT_HISTORY_READ_TIME_COL) #------------\n",
    "#         .pipe(\n",
    "#             truncate_history,\n",
    "#             column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "#             history_size=history_size,\n",
    "#             padding_value=0,\n",
    "#             enable_warning=False,\n",
    "#         )\n",
    "#     )\n",
    "#     df_behaviors = (\n",
    "#         pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "#         .collect()\n",
    "#         .pipe(\n",
    "#             slice_join_dataframes,\n",
    "#             df2=df_history.collect(),\n",
    "#             on=DEFAULT_USER_COL,\n",
    "#             how=\"left\",\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     return df_behaviors\n",
    "\n",
    "\n",
    "def ebnerd_from_path(\n",
    "    path: Path,\n",
    "    history_size: int = 30,\n",
    "    padding: int = 0,\n",
    "    user_col: str = DEFAULT_USER_COL,\n",
    "    history_aids_col: str = DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(user_col, history_aids_col)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=history_aids_col,\n",
    "            history_size=history_size,\n",
    "            padding_value=padding,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=user_col,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "  \n",
    "#-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "  ### Generate labels\n",
    "#-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "# We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels.\n",
    "\n",
    "PATH = Path(\"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data\").expanduser()\n",
    "DATASPLIT = \"ebnerd_small\" # TODO if change to change make_embedding_artifacts.ipynb file (embeddings)\n",
    "\n",
    "# DATASPLIT = \"ebnerd__testset\"\n",
    "DUMP_DIR = PATH.joinpath(\"dump_artifacts\")\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "#In this example we sample the dataset, just to keep it smaller. Also, one can simply add the testset similary to the validation.\n",
    "\n",
    "### Define the Data Cols -- New ones here\n",
    "# COLUMNS = [\n",
    "#     DEFAULT_USER_COL,\n",
    "#     DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "#     DEFAULT_HISTORY_SCROLL_PERCENTAGE_COL, #--------neu \n",
    "#     DEFAULT_HISTORY_READ_TIME_COL, #------- neu\n",
    "#     DEFAULT_INVIEW_ARTICLES_COL,\n",
    "#     DEFAULT_CLICKED_ARTICLES_COL,\n",
    "#     DEFAULT_IMPRESSION_ID_COL,\n",
    "#     DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "# ]\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "\n",
    "\n",
    "print(\"____————____————____————____———\")\n",
    "print(\"HISTORY_SIZE:\", HISTORY_SIZE)\n",
    "print(\"FRACTION:\", FRACTION)\n",
    "print(\"EPOCHS:\", EPOCHS)\n",
    "print(\"FRACTION_testset:\", FRACTION_testset)\n",
    "print(\"____————____————____————____———\")\n",
    "print(\"\")\n",
    "#____————____————____————____————\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=6,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "print(df_train.head(2))\n",
    "print(df_validation.head(2))\n",
    "\n",
    "\n",
    "#-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "## Load articles\n",
    "#-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "df_articles = pl.read_parquet(PATH.joinpath(DATASPLIT, \"articles.parquet\"))\n",
    "df_articles.head(2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "\n",
    "# # Loading the article embeddings and other feature stuff\n",
    "\n",
    "# #-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "\n",
    "# ### Added features and hourly difference between published and viewed article\n",
    "\n",
    "# ## NEW\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Convert polars DataFrame to pandas\n",
    "# df_train = df_train.to_pandas()\n",
    "\n",
    "# # Create a mapping dictionary from article_id to last_modified_time\n",
    "# article_time_dict = df_articles.select(\n",
    "#     \"article_id\", \n",
    "#     \"published_time\"\n",
    "# ).to_dict(as_series=False)\n",
    "# article_time_dict = dict(zip(\n",
    "#     article_time_dict[\"article_id\"], \n",
    "#     article_time_dict[\"published_time\"]\n",
    "# ))\n",
    "\n",
    "# # Create a function to map article IDs to their timestamps\n",
    "# def get_article_times(article_ids):\n",
    "#     return [article_time_dict.get(aid, None) for aid in article_ids]\n",
    "\n",
    "# # Add new column with the published-time\n",
    "# df_train[\"inview_article_times\"] = df_train[\"article_ids_inview\"].apply(get_article_times)\n",
    "\n",
    "# #add new column with the last publish_time for the clicked article\n",
    "# df_train[\"clicked_article_time\"] = df_train[\"article_ids_clicked\"].apply(get_article_times)\n",
    "\n",
    "# # Create a function to calculate hour differences\n",
    "# def calculate_hour_differences(impression_time, article_times):\n",
    "#         # If article_times is a single value (for clicked articles)\n",
    "#     if not isinstance(article_times, list):\n",
    "#         if article_times is None:\n",
    "#             return None\n",
    "#         return (impression_time - article_times).total_seconds() / 3600\n",
    "    \n",
    "#     # If article_times is a list (for inview articles)\n",
    "#     differences = [(impression_time - article_time).total_seconds() / 3600 \n",
    "#                   if article_time is not None else None \n",
    "#                   for article_time in article_times]\n",
    "#     return differences\n",
    "\n",
    "# # Use for inview articles\n",
    "# df_train['inview_hour_differences'] = df_train.apply(\n",
    "#     lambda row: calculate_hour_differences(row['impression_time'], row['inview_article_times']), \n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # # Use for clicked article\n",
    "# # df_train['clicked_hour_difference'] = df_train.apply(\n",
    "# #    lambda row: calculate_hour_differences(row['impression_time'], row['clicked_article_time']), \n",
    "# #    axis=1\n",
    "# # )\n",
    "\n",
    "# # Create a mapping dictionary from article_id to last_modified_category\n",
    "# article_cat_dict = df_articles.select(\n",
    "#     \"article_id\", \n",
    "#     \"category\"\n",
    "# ).to_dict(as_series=False)\n",
    "# article_cat_dict = dict(zip(\n",
    "#     article_cat_dict[\"article_id\"], \n",
    "#     article_cat_dict[\"category\"]\n",
    "# ))\n",
    "\n",
    "# # Create a function to map article IDs to their category\n",
    "# def get_article_category(article_ids):\n",
    "#     return [article_cat_dict.get(aid, None) for aid in article_ids]\n",
    "\n",
    "# #  Add new column with the article category\n",
    "# df_train[\"inview_article_categories\"] = df_train[\"article_ids_inview\"].apply(get_article_category)\n",
    "\n",
    "# df_train[\"history_article_categories\"] = df_train[\"article_id_fixed\"].apply(get_article_category)\n",
    "\n",
    "# # Create a mapping dictionary from article_id to article_type\n",
    "# article_type_dict = df_articles.select(\n",
    "#     \"article_id\", \n",
    "#     \"article_type\"\n",
    "# ).to_dict(as_series=False)\n",
    "# article_type_dict = dict(zip(\n",
    "#     article_type_dict[\"article_id\"], \n",
    "#     article_type_dict[\"article_type\"]\n",
    "# ))\n",
    "\n",
    "# # Create a function to map article IDs to their type\n",
    "# def get_article_type(article_ids):\n",
    "#     return [article_type_dict.get(aid, None) for aid in article_ids]\n",
    "\n",
    "# # Add new column with the article type\n",
    "# df_train[\"inview_article_types\"] = df_train[\"article_ids_inview\"].apply(get_article_type)\n",
    "\n",
    "# df_train[\"history_article_types\"] = df_train[\"article_id_fixed\"].apply(get_article_type)\n",
    "\n",
    "# #drop columns with the time\n",
    "# df_train = df_train.drop(['inview_article_times', 'clicked_article_time','impression_time'], axis=1)\n",
    "\n",
    "# df_train = pl.from_pandas(df_train)\n",
    "\n",
    "# df_train.head(2)\n",
    "\n",
    "\n",
    "# ##########################################################################################\n",
    "\n",
    "\n",
    "# # Convert polars DataFrame to pandas\n",
    "# df_validation = df_validation.to_pandas()\n",
    "\n",
    "# # Create a mapping dictionary from article_id to last_modified_time\n",
    "# article_time_dict = df_articles.select(\n",
    "#     \"article_id\", \n",
    "#     \"published_time\"\n",
    "# ).to_dict(as_series=False)\n",
    "# article_time_dict = dict(zip(\n",
    "#     article_time_dict[\"article_id\"], \n",
    "#     article_time_dict[\"published_time\"]\n",
    "# ))\n",
    "\n",
    "# # Create a function to map article IDs to their timestamps\n",
    "# def get_article_times(article_ids):\n",
    "#     return [article_time_dict.get(aid, None) for aid in article_ids]\n",
    "\n",
    "# # Add new column with the published-time\n",
    "# df_validation[\"inview_article_times\"] = df_validation[\"article_ids_inview\"].apply(get_article_times)\n",
    "\n",
    "# #add new column with the last publish_time for the clicked article\n",
    "# df_validation[\"clicked_article_time\"] = df_validation[\"article_ids_clicked\"].apply(get_article_times)\n",
    "\n",
    "# # Create a function to calculate hour differences\n",
    "# def calculate_hour_differences(impression_time, article_times):\n",
    "#         # If article_times is a single value (for clicked articles)\n",
    "#     if not isinstance(article_times, list):\n",
    "#         if article_times is None:\n",
    "#             return None\n",
    "#         return (impression_time - article_times).total_seconds() / 3600\n",
    "    \n",
    "#     # If article_times is a list (for inview articles)\n",
    "#     differences = [(impression_time - article_time).total_seconds() / 3600 \n",
    "#                   if article_time is not None else None \n",
    "#                   for article_time in article_times]\n",
    "#     return differences\n",
    "\n",
    "# # Use for inview articles\n",
    "# df_validation['inview_hour_differences'] = df_validation.apply(\n",
    "#     lambda row: calculate_hour_differences(row['impression_time'], row['inview_article_times']), \n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # # Use for clicked article -- might be leaky??\n",
    "# # df_validation['clicked_hour_difference'] = df_validation.apply(\n",
    "# #    lambda row: calculate_hour_differences(row['impression_time'], row['clicked_article_time']), \n",
    "# #    axis=1\n",
    "# # )\n",
    "# # Create a mapping dictionary from article_id to last_modified_category\n",
    "# article_cat_dict = df_articles.select(\n",
    "#     \"article_id\", \n",
    "#     \"category\"\n",
    "# ).to_dict(as_series=False)\n",
    "# article_cat_dict = dict(zip(\n",
    "#     article_cat_dict[\"article_id\"], \n",
    "#     article_cat_dict[\"category\"]\n",
    "# ))\n",
    "\n",
    "# # Create a function to map article IDs to their category\n",
    "# def get_article_category(article_ids):\n",
    "#     return [article_cat_dict.get(aid, None) for aid in article_ids]\n",
    "\n",
    "# #  Add new column with the article category\n",
    "# df_validation[\"inview_article_categories\"] = df_validation[\"article_ids_inview\"].apply(get_article_category)\n",
    "\n",
    "# df_validation[\"history_article_categories\"] = df_validation[\"article_id_fixed\"].apply(get_article_category)\n",
    "\n",
    "# # Create a mapping dictionary from article_id to article_type\n",
    "# article_type_dict = df_articles.select(\n",
    "#     \"article_id\", \n",
    "#     \"article_type\"\n",
    "# ).to_dict(as_series=False)\n",
    "# article_type_dict = dict(zip(\n",
    "#     article_type_dict[\"article_id\"], \n",
    "#     article_type_dict[\"article_type\"]\n",
    "# ))\n",
    "\n",
    "# # Create a function to map article IDs to their type\n",
    "# def get_article_type(article_ids):\n",
    "#     return [article_type_dict.get(aid, None) for aid in article_ids]\n",
    "\n",
    "# # Add new column with the article type\n",
    "# df_validation[\"inview_article_types\"] = df_validation[\"article_ids_inview\"].apply(get_article_type)\n",
    "\n",
    "# df_validation[\"history_article_types\"] = df_validation[\"article_id_fixed\"].apply(get_article_type)\n",
    "\n",
    "\n",
    "# #drop columns with the time\n",
    "# df_validation = df_validation.drop(['inview_article_times', 'clicked_article_time','impression_time'], axis=1)\n",
    "\n",
    "\n",
    "# df_validation = pl.from_pandas(df_validation)\n",
    "\n",
    "# df_validation.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____————____————____————____———\n",
      "Using transformer model: Maltehb/danish-bert-botxo\n",
      "____————____————____————____———\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "\n",
    "# In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "# Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n",
    "#-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "\n",
    "# TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "# TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-robe rta-large\"\n",
    "# TRANSFORMER_MODEL_NAME = \"google-bert/bert-base-multilingual-uncased\" \n",
    "#Argue for cased vs uncased.  TODO\n",
    "# #Cased might be better but to compare with malteHb we use uncased\n",
    "\n",
    "TRANSFORMER_MODEL_NAME = \"Maltehb/danish-bert-botxo\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30 #hardcoded somewhere ?? error if change\n",
    "\n",
    "print(\"\")\n",
    "print(\"____————____————____————____———\")\n",
    "print(\"Using transformer model:\", TRANSFORMER_MODEL_NAME)\n",
    "print(\"____————____————____————____———\")\n",
    "print(\"\")\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "\n",
    "\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")\n",
    "\n",
    "#_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "\n",
    "# print(\"df_train columns:\", df_train.columns)\n",
    "# print(\"df_validation columns:\", df_validation.columns)\n",
    "#_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=128,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=64,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: []\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# List all physical devices\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available devices:\", physical_devices)\n",
    "import torch.nn as nn\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]:   0%|          | 0/184 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 184/184 [00:26<00:00,  6.90it/s, loss=0.3976]\n",
      "Epoch 1/3 [Valid]: 100%|██████████| 383/383 [01:22<00:00,  4.62it/s, loss=0.6304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.3976, Val Loss: 0.3028\n",
      "\n",
      "Validation loss improved from inf to 0.30284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 184/184 [00:26<00:00,  6.88it/s, loss=0.3811]\n",
      "Epoch 2/3 [Valid]: 100%|██████████| 383/383 [01:23<00:00,  4.59it/s, loss=0.6641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Loss: 0.3811, Val Loss: 0.3190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 184/184 [00:26<00:00,  6.85it/s, loss=0.3737]\n",
      "Epoch 3/3 [Valid]: 100%|██████████| 383/383 [01:23<00:00,  4.61it/s, loss=0.7010]\n",
      "/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/src/ebrec/models/newsrec/nrmspy_1.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(filepath))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Loss: 0.3737, Val Loss: 0.3368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 383/383 [01:23<00:00,  4.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "# Original Model\n",
    "# _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
    "\n",
    "# Works fine -- Can change epochs on line 67\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "WEIGHTS_DIR = f\"downloads/data/state_dict/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = f\"{WEIGHTS_DIR}/weights.pt\"\n",
    "\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "# Create a custom ModelCheckpoint for PyTorch\n",
    "class PyTorchModelCheckpoint:\n",
    "    def __init__(self, filepath, model_wrapper=None, save_best_only=True, save_weights_only=True, verbose=1):\n",
    "        self.filepath = filepath\n",
    "        self.model_wrapper = model_wrapper  # Store the model wrapper reference\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.verbose = verbose\n",
    "        self.best_val_loss = float('inf')\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs.get('val_loss', None)\n",
    "        if val_loss is None:\n",
    "            return\n",
    "        \n",
    "        if self.save_best_only:\n",
    "            if val_loss < self.best_val_loss:\n",
    "                if self.verbose:\n",
    "                    print(f'\\nValidation loss improved from {self.best_val_loss:.5f} to {val_loss:.5f}')\n",
    "                self.best_val_loss = val_loss\n",
    "                # Use the model_wrapper reference\n",
    "                self.model_wrapper.save_weights(self.filepath)\n",
    "        else:\n",
    "            self.model_wrapper.save_weights(self.filepath)\n",
    "\n",
    "# Initialize model first\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "\n",
    "# Best hyperparameters: {'head_num': 19, 'head_dim': 29, 'attention_hidden_dim': 145, 'dropout': 0.22088583494496855, 'learning_rate': 0.00030309205322750723}\n",
    "\n",
    "hparams_nrms.head_num = 19\n",
    "hparams_nrms.head_dim = 29\n",
    "hparams_nrms.attention_hidden_dim = 145\n",
    "hparams_nrms.dropout = 0.22088583494496855\n",
    "hparams_nrms.learning_rate = 0.00030309205322750723\n",
    "\n",
    "pytorch_model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "model = NRMSWrapper(pytorch_model)\n",
    "\n",
    "# Then create the callback with the model reference\n",
    "modelcheckpoint = PyTorchModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS,\n",
    "    model_wrapper=model,  # Pass the model wrapper\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Training\n",
    "hist = model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=EPOCHS, ### EPOCHS INPUT\n",
    "    callbacks=[modelcheckpoint]\n",
    ")\n",
    "\n",
    "# Load weights using the wrapper\n",
    "model.load_weights(filepath=MODEL_WEIGHTS)\n",
    "\n",
    "# Get predictions\n",
    "pred_validation = model.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE ⛄️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 20156\n",
      "Validation samples: 3271\n",
      "Fraction of test data: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# NEW (OLD) CODE\n",
    "\n",
    "import datetime\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "df = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(DATASPLIT, \"train\"),\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding=0,\n",
    "    )\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "dt_split = pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL).max() - datetime.timedelta(days=1)\n",
    "df_train = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) < dt_split)\n",
    "df_validation = df.filter(pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL) >= dt_split)\n",
    "\n",
    "print(f\"Train samples: {df_train.height}\\nValidation samples: {df_validation.height}\")\n",
    "df_train.head(2)\n",
    "\n",
    "PATH= Path(\"/dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data\").expanduser()\n",
    "datasplit=\"ebnerd_testset\"\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    # DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "]\n",
    "\n",
    "df_test = (\n",
    "    ebnerd_from_path(\n",
    "        PATH.joinpath(datasplit, \"test\"),\n",
    "        # PATH.joinpath(DATASPLIT, \"validation\"),\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding=0,\n",
    "    )\n",
    "    .select(COLUMNS)\n",
    "    # .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION_testset)\n",
    ")\n",
    "print(\"Fraction of test data:\", FRACTION_testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummny labels that get removed in the Dataloader anyways\n",
    "\n",
    "df_test = df_test.with_columns(pl.lit(0).alias(\"labels\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TEST = 32\n",
    "\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=BATCH_SIZE_TEST,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started doing predictions on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 43/43 [00:06<00:00,  6.35it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Started doing predictions on testset\")\n",
    "pred_test = model.scorer.predict(test_dataloader)\n",
    "df_test = add_prediction_scores(df_test, pred_test.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = MetricEvaluator(\n",
    "#     labels=df_test[\"labels\"].to_list(),\n",
    "#     predictions=df_test[\"scores\"].to_list(),\n",
    "#     metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    "# )\n",
    "# metrics.evaluate() ### IT IS SUPPOSDD TO BE COMMENTED OUT -- cant run metrics on unlabeled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make submissions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>impression_id</th><th>impression_time</th><th>article_id_fixed</th><th>article_ids_inview</th><th>labels</th><th>scores</th><th>ranked_scores</th></tr><tr><td>u32</td><td>u32</td><td>datetime[μs]</td><td>list[i32]</td><td>list[i32]</td><td>i32</td><td>list[f64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>1865414</td><td>29513300</td><td>2023-06-02 14:57:18</td><td>[9779511, 9778939, … 9203696]</td><td>[8054212, 9778257, … 9794017]</td><td>0</td><td>[0.028204, 0.1812, … 0.203133]</td><td>[5, 2, … 1]</td></tr><tr><td>73278</td><td>281985418</td><td>2023-06-04 08:18:40</td><td>[9789446, 9788116, … 9789832]</td><td>[9795545, 9790335, … 9796792]</td><td>0</td><td>[0.089995, 0.126175, … 0.110625]</td><td>[4, 2, … 3]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 8)\n",
       "┌─────────┬─────────────┬─────────────┬────────────┬────────────┬────────┬────────────┬────────────┐\n",
       "│ user_id ┆ impression_ ┆ impression_ ┆ article_id ┆ article_id ┆ labels ┆ scores     ┆ ranked_sco │\n",
       "│ ---     ┆ id          ┆ time        ┆ _fixed     ┆ s_inview   ┆ ---    ┆ ---        ┆ res        │\n",
       "│ u32     ┆ ---         ┆ ---         ┆ ---        ┆ ---        ┆ i32    ┆ list[f64]  ┆ ---        │\n",
       "│         ┆ u32         ┆ datetime[μs ┆ list[i32]  ┆ list[i32]  ┆        ┆            ┆ list[i64]  │\n",
       "│         ┆             ┆ ]           ┆            ┆            ┆        ┆            ┆            │\n",
       "╞═════════╪═════════════╪═════════════╪════════════╪════════════╪════════╪════════════╪════════════╡\n",
       "│ 1865414 ┆ 29513300    ┆ 2023-06-02  ┆ [9779511,  ┆ [8054212,  ┆ 0      ┆ [0.028204, ┆ [5, 2, …   │\n",
       "│         ┆             ┆ 14:57:18    ┆ 9778939, … ┆ 9778257, … ┆        ┆ 0.1812, …  ┆ 1]         │\n",
       "│         ┆             ┆             ┆ 9203696]   ┆ 9794017]   ┆        ┆ 0.203133]  ┆            │\n",
       "│ 73278   ┆ 281985418   ┆ 2023-06-04  ┆ [9789446,  ┆ [9795545,  ┆ 0      ┆ [0.089995, ┆ [4, 2, …   │\n",
       "│         ┆             ┆ 08:18:40    ┆ 9788116, … ┆ 9790335, … ┆        ┆ 0.126175,  ┆ 3]         │\n",
       "│         ┆             ┆             ┆ 9789832]   ┆ 9796792]   ┆        ┆ …          ┆            │\n",
       "│         ┆             ┆             ┆            ┆            ┆        ┆ 0.110625]  ┆            │\n",
       "└─────────┴─────────────┴─────────────┴────────────┴────────────┴────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.with_columns(\n",
    "    pl.col(\"scores\")\n",
    "    .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "    .alias(\"ranked_scores\")\n",
    ")\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1353it [00:00, 23575.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping /dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/dump_artifacts/predictions.txt to /dtu/blackhole/14/155764/DeepL-Project-Corn2/ebnerd-benchmark-copy/ebnerd_data/dump_artifacts/predictions__.zip\n",
      "Submission file created!\n",
      "DONE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_submission_file(\n",
    "    impression_ids=df_test[DEFAULT_IMPRESSION_ID_COL],\n",
    "    prediction_scores=df_test[\"ranked_scores\"],\n",
    "    path=DUMP_DIR.joinpath(\"predictions.txt\"),\n",
    "    filename_zip=f\"predictions__.zip\",\n",
    ")\n",
    "print(\"Submission file created!\")\n",
    "print(\"DONE\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merry Christmas!\n",
      "    *  *  \n",
      "  *  -  - *\n",
      "   / O  O \\ \n",
      "  (    >    )\n",
      "   \\ '===' /\n",
      "   /|     |\\\n",
      "  /_|     |_\\\n"
     ]
    }
   ],
   "source": [
    "print(\"Merry Christmas!\")\n",
    "print(\"    *  *  \")\n",
    "print(\"  *  -  - *\")\n",
    "print(\"   / O  O \\\\ \")\n",
    "print(\"  (    >    )\")\n",
    "print(\"   \\\\ '===' /\")\n",
    "print(\"   /|     |\\\\\")\n",
    "print(\"  /_|     |_\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW SHIT that is shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_FRACITON=0.002\n",
    "# DEFAULT_IS_BEYOND_ACCURACY_COL = \"is_beyond_accuracy\"\n",
    "# from ebrec.utils._polars import split_df_chunks, concat_str_columns\n",
    "\n",
    "# NUM_CHUNKS_TEST = 10\n",
    "# CHUNKS_DONE = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating testset...\n",
      "Initiating testset without beyond-accuracy...\n"
     ]
    }
   ],
   "source": [
    "# # =====================================================================================\n",
    "# print(\"Initiating testset...\")\n",
    "# df_test = (\n",
    "#     ebnerd_from_path(\n",
    "#         PATH.joinpath(\"ebnerd_testset\", \"test\"),\n",
    "#         history_size=HISTORY_SIZE,\n",
    "#         padding=0,\n",
    "#     )\n",
    "#     .sample(fraction=TEST_FRACITON)\n",
    "#     .with_columns(\n",
    "#         pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "#         .list.first()\n",
    "#         .alias(DEFAULT_CLICKED_ARTICLES_COL)\n",
    "#     )\n",
    "#     .select(COLUMNS + [DEFAULT_IS_BEYOND_ACCURACY_COL])\n",
    "#     .with_columns(\n",
    "#         pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "#         .list.eval(pl.element() * 0)\n",
    "#         .alias(DEFAULT_LABELS_COL)\n",
    "#     )\n",
    "# )\n",
    "# # Split test in beyond-accuracy TRUE / FALSE. In the BA 'article_ids_inview' is 250.\n",
    "# df_test_wo_beyond = df_test.filter(~pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "# df_test_w_beyond = df_test.filter(pl.col(DEFAULT_IS_BEYOND_ACCURACY_COL))\n",
    "\n",
    "# df_test_chunks = split_df_chunks(df_test_wo_beyond, n_chunks=NUM_CHUNKS_TEST)\n",
    "# df_pred_test_wo_beyond = []\n",
    "# print(\"Initiating testset without beyond-accuracy...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test_w_beyond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26680, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test_wo_beyond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE_TEST_WO_B = 32\n",
    "# BATCH_SIZE_TEST_W_B = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime as dt\n",
    "# # Dump paths:\n",
    "# DUMP_DIR = Path(\"ebnerd_predictions\")\n",
    "# DUMP_DIR.mkdir(exist_ok=True, parents=True)\n",
    "# #\n",
    "# DT_NOW = dt.datetime.now()\n",
    "# #\n",
    "# MODEL_NAME =\"NRMS_MODEL\"\n",
    "# MODEL_OUTPUT_NAME = f\"{MODEL_NAME}-{DT_NOW}\"\n",
    "# #\n",
    "# ARTIFACT_DIR = DUMP_DIR.joinpath(\"test_predictions\", MODEL_OUTPUT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_CHUNKS_DIR = ARTIFACT_DIR.joinpath(\"test_chunks\")\n",
    "# TEST_CHUNKS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chunk: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 84/84 [00:09<00:00,  8.68it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for i, df_test_chunk in enumerate(df_test_chunks[CHUNKS_DONE:], start=1 + CHUNKS_DONE):\n",
    "#     print(f\"Test chunk: {i}/{len(df_test_chunks)}\")\n",
    "#     # Initialize DataLoader\n",
    "#     test_dataloader_wo_b = NRMSDataLoader(\n",
    "#         behaviors=df_test_chunk,\n",
    "#         article_dict=article_mapping,\n",
    "#         unknown_representation=\"zeros\",\n",
    "#         history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "#         eval_mode=True,\n",
    "#         batch_size=BATCH_SIZE_TEST_WO_B,\n",
    "#     )\n",
    "#     # Predict and clear session\n",
    "#     scores = model.scorer.predict(test_dataloader_wo_b)\n",
    "#     tf.keras.backend.clear_session()\n",
    "\n",
    "#     # Process the predictions\n",
    "#     df_test_chunk = add_prediction_scores(df_test_chunk, scores.tolist()).with_columns(\n",
    "#         pl.col(\"scores\")\n",
    "#         .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "#         .alias(\"ranked_scores\")\n",
    "#     )\n",
    "\n",
    "#     # Save the processed chunk\n",
    "#     df_test_chunk.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "#         TEST_CHUNKS_DIR.joinpath(f\"pred_wo_ba_{i}.parquet\")\n",
    "#     )\n",
    "\n",
    "#     # Append and clean up\n",
    "#     df_pred_test_wo_beyond.append(df_test_chunk)\n",
    "\n",
    "#     # Cleanup\n",
    "#     del df_test_chunk, test_dataloader_wo_b, scores\n",
    "#     gc.collect()\n",
    "\n",
    "# df_pred_test_wo_beyond = pl.concat(df_pred_test_wo_beyond)\n",
    "# df_pred_test_wo_beyond.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "#     TEST_CHUNKS_DIR.joinpath(\"pred_wo_ba.parquet\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating testset without beyond-accuracy...\n"
     ]
    }
   ],
   "source": [
    "# df_test_w_beyond_chunks = split_df_chunks(df_test_w_beyond, n_chunks=NUM_CHUNKS_TEST)\n",
    "# df_pred_test_w_beyond = []\n",
    "# print(\"Initiating testset without beyond-accuracy...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, df_test_w_beyond_chunk in enumerate(df_test_w_beyond_chunks[CHUNKS_DONE:], start=1 + CHUNKS_DONE):\n",
    "#     print(f\"Test chunk: {i}/{len(df_test_w_beyond_chunks)}\")\n",
    "#     # Initialize DataLoader\n",
    "#     test_dataloader_w_b = NRMSDataLoader(\n",
    "#         behaviors=df_test_w_beyond_chunk,\n",
    "#         article_dict=article_mapping,\n",
    "#         unknown_representation=\"zeros\",\n",
    "#         history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "#         eval_mode=True,\n",
    "#         batch_size=BATCH_SIZE_TEST_W_B,\n",
    "#     )\n",
    "#     # Predict and clear session\n",
    "#     scores = model.scorer.predict(test_dataloader_w_b)\n",
    "#     tf.keras.backend.clear_session()\n",
    "\n",
    "#     # Process the predictions\n",
    "#     df_test_w_beyond_chunk = add_prediction_scores(\n",
    "#         df_test_w_beyond_chunk, scores.tolist()\n",
    "#     ).with_columns(\n",
    "#         pl.col(\"scores\")\n",
    "#         .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "#         .alias(\"ranked_scores\")\n",
    "#     )\n",
    "\n",
    "#     # Save the processed chunk\n",
    "#     df_test_w_beyond_chunk.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "#         TEST_CHUNKS_DIR.joinpath(f\"pred_w_ba_{i}.parquet\")\n",
    "#     )\n",
    "\n",
    "#     # Append and clean up\n",
    "#     df_pred_test_w_beyond.append(df_test_w_beyond_chunk)\n",
    "\n",
    "#     # Cleanup\n",
    "#     del df_test_w_beyond_chunk, test_dataloader_w_b, scores\n",
    "#     gc.collect()\n",
    "\n",
    "# df_pred_test_w_beyond = pl.concat(df_pred_test_w_beyond)\n",
    "# df_pred_test_w_beyond.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "#     TEST_CHUNKS_DIR.joinpath(\"pred_w_ba.parquet\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # =====================================================================================\n",
    "# print(\"Initiating testset with beyond-accuracy...\")\n",
    "# test_dataloader_w_b = NRMSDataLoader(\n",
    "#     behaviors=df_test_w_beyond,\n",
    "#     article_dict=article_mapping,\n",
    "#     unknown_representation=\"zeros\",\n",
    "#     history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "#     eval_mode=True,\n",
    "#     batch_size=BATCH_SIZE_TEST_W_B,\n",
    "# )\n",
    "# scores = model.scorer.predict(test_dataloader_w_b)\n",
    "# df_pred_test_w_beyond = add_prediction_scores(\n",
    "#     df_test_w_beyond, scores.tolist()\n",
    "# ).with_columns(\n",
    "#     pl.col(\"scores\")\n",
    "#     .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "#     .alias(\"ranked_scores\")\n",
    "# )\n",
    "# df_pred_test_w_beyond.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "#     TEST_CHUNKS_DIR.joinpath(\"pred_w_ba.parquet\")\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # =====================================================================================\n",
    "# print(\"Saving prediction results...\")\n",
    "# df_test = pl.concat([df_pred_test_wo_beyond, df_pred_test_w_beyond])\n",
    "# df_test.select(DEFAULT_IMPRESSION_ID_COL, \"ranked_scores\").write_parquet(\n",
    "#     ARTIFACT_DIR.joinpath(\"test_predictions.parquet\")\n",
    "# )\n",
    "\n",
    "# if TEST_CHUNKS_DIR.exists() and TEST_CHUNKS_DIR.is_dir():\n",
    "#     shutil.rmtree(TEST_CHUNKS_DIR)\n",
    "\n",
    "# write_submission_file(\n",
    "#     impression_ids=df_test[DEFAULT_IMPRESSION_ID_COL],\n",
    "#     prediction_scores=df_test[\"ranked_scores\"],\n",
    "#     path=ARTIFACT_DIR.joinpath(\"predictions.txt\"),\n",
    "#     filename_zip=f\"{MODEL_NAME}-{SEED}-{DATASPLIT}.zip\",\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
