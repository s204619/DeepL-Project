{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path_turing = './unilmv2'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.insert(0, './PLM-NR')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tnlrv3.modeling import TuringNLRv3ForSequenceClassification\n",
    "from tnlrv3.configuration_tnlrv3 import TuringNLRv3Config\n",
    "from tnlrv3.tokenization_tnlrv3 import TuringNLRv3Tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenizer = TuringNLRv3Tokenizer.from_pretrained(os.path.join(path_turing, 'unilm2-base-uncased-vocab.txt'),\n",
    "                                            do_lower_case=True)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MODEL_CLASSES = {\n",
    "    'tnlrv3': (TuringNLRv3Config, TuringNLRv3ForSequenceClassification, TuringNLRv3Tokenizer),\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrain Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MAX_TEXT_LEN = 512\n",
    "BATCH_SIZE = 32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file = './docs_filter.tsv'\n",
    "with open(file, encoding='utf-8') as f:\n",
    "    total_lines = f.readlines()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(total_lines)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corpus = []\n",
    "for line in total_lines:\n",
    "    splited = line.strip('\\n').split('\\t')\n",
    "    nid,cate,subcate,title, body,abstract,url,time = splited\n",
    "    corpus.append(body)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrain Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        self.len = len(corpus)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.corpus[idx]\n",
    "        tokenized_text = tokenizer(text, max_length=MAX_TEXT_LEN, pad_to_max_length=True, truncation=True)\n",
    "        input_ids = np.array(tokenized_text['input_ids'])\n",
    "        attn_mask = np.array(tokenized_text['attention_mask'])\n",
    "        processed_ids, masked_lm_labels = self.create_masked_lm_labels(input_ids)\n",
    "        return processed_ids, attn_mask, masked_lm_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def create_masked_lm_labels(self, tokens):\n",
    "        processed_ids = np.array(tokens)\n",
    "        total_len = np.sum(tokens > 0)\n",
    "        candi_index = list(range(1, total_len - 1))\n",
    "        num_to_predict = max(1, int(np.floor((total_len - 2) * 0.15)))\n",
    "\n",
    "        selected_index = random.sample(candi_index, k=num_to_predict)\n",
    "        masked_lm_labels = np.array([-1] * len(tokens))\n",
    "\n",
    "        for i in selected_index:\n",
    "            masked_lm_labels[i] = tokens[i]\n",
    "            if random.random() < 0.8:\n",
    "                masked_token = 104\n",
    "            else:\n",
    "            # 10% of the time, keep original\n",
    "                if random.random() < 0.5:\n",
    "                    masked_token = tokens[i]\n",
    "            # 10% of the time, replace with random word\n",
    "                else:\n",
    "                    masked_token = random.randint(0, 30521)\n",
    "            processed_ids[i] = masked_token\n",
    "        \n",
    "        return processed_ids, masked_lm_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pretrain_ds = PretrainDataset(corpus)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pretrain_dl = DataLoader(pretrain_ds, batch_size=BATCH_SIZE, num_workers=32, shuffle=True, pin_memory=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrain Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from utils import MODEL_CLASSES\n",
    "from tnlrv3.modeling import BertOnlyMLMHead\n",
    "\n",
    "def init_weights(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.fill_(1.0)\n",
    "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "        module.bias.data.zero_()\n",
    "        \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Model, self).__init__()\n",
    "        config_class, model_class, tokenizer_class = MODEL_CLASSES['tnlrv3']\n",
    "        self.bert_config = config_class.from_pretrained(\n",
    "            args.config_name,\n",
    "            num_hidden_layers=args.num_hidden_layers)\n",
    "        self.bert_model = model_class.from_pretrained(args.model_name, config=self.bert_config)\n",
    "        self.cls = BertOnlyMLMHead(self.bert_config, self.bert_model.bert.embeddings.word_embeddings.weight)\n",
    "        self.cls.apply(init_weights)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, masked_lm_labels):\n",
    "        sequence_output = self.bert_model(input_ids, attention_mask)[1]\n",
    "        prediction_scores = self.cls(sequence_output)\n",
    "\n",
    "        masked_lm_loss = self.loss_fn(prediction_scores.view(-1, self.bert_config.vocab_size), masked_lm_labels.view(-1))\n",
    "        return masked_lm_loss, prediction_scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.model_name = os.path.join(path_turing, 'unilm2-base-uncased.bin')\n",
    "        self.num_hidden_layers = 12\n",
    "        self.config_name = os.path.join(path_turing, 'unilm2-base-uncased-config.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "args = Args()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pretrain_model = Model(args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device('cuda')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pretrain_model.to(device)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = torch.argmax(y_hat, dim=-1)\n",
    "    tot = torch.sum(y_true != -1)\n",
    "    hit = torch.sum((y_true == y_hat) & (y_true != -1))\n",
    "    return hit.data.float() * 1.0 / tot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for param in pretrain_model.bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for index, layer in enumerate(pretrain_model.bert_model.bert.encoder.layer):\n",
    "    if index in [9, 10, 11]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for name, p in pretrain_model.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rest_param = filter(\n",
    "    lambda x: id(x) not in list(map(id, pretrain_model.bert_model.parameters())), pretrain_model.parameters())\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    [{'params':pretrain_model.bert_model.parameters(),'lr':1e-6},\n",
    "    {'params':rest_param,'lr':1e-5}]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for ep in range(1):\n",
    "    loss = 0.0\n",
    "    accuary = 0.0\n",
    "    cnt = 0\n",
    "    tqdm_util = tqdm(pretrain_dl)\n",
    "    pretrain_model.train()\n",
    "    for input_ids, attn_mask, mlm_labels in tqdm_util: \n",
    "        input_ids = input_ids.to(device)\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        mlm_labels = mlm_labels.to(device)\n",
    "        \n",
    "        bz_loss, y_hat = pretrain_model(input_ids, attn_mask, mlm_labels)\n",
    "        loss += bz_loss.data.float()\n",
    "        bz_acc = acc(mlm_labels, y_hat)\n",
    "        accuary += bz_acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        bz_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if cnt % 10 == 0:\n",
    "            tqdm_util.set_description('ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(cnt * BATCH_SIZE, loss.data / cnt, accuary / cnt))\n",
    "        \n",
    "        cnt += 1\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ckpt_path = './FP_12_layer.pt'\n",
    "torch.save({'model_state_dict': pretrain_model.state_dict()}, ckpt_path)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d59988123833fd073d3bb571862451a431b21510e4476893f23b2d4367207ad1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}