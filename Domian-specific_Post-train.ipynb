{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.6.0\n",
      "  Using cached torch-1.6.0-cp38-none-macosx_10_9_x86_64.whl (97.5 MB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.15.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.15.0\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: numpy in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (1.19.2)\n",
      "Requirement already satisfied: tqdm in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (4.65.0)\n",
      "Requirement already satisfied: torchvision in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (0.8.2)\n",
      "Requirement already satisfied: torchaudio in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (1.19.2)\n",
      "Requirement already satisfied: tqdm in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (4.65.0)\n",
      "Requirement already satisfied: transformers in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (4.46.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: pickle5 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (0.0.11)\n",
      "Requirement already satisfied: torch in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: filelock in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from torch->torchvision) (3.9.0)\n",
      "Requirement already satisfied: sympy in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from torch->torchvision) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from torch->torchvision) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from torch->torchvision) (3.1.2)\n",
      "Requirement already satisfied: networkx in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from torch->torchvision) (2.8.4)\n",
      "Requirement already satisfied: fsspec in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from torch->torchvision) (2024.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from jinja2->torch->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages (from sympy->torch->torchvision) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0 tensorflow==1.15.0 horovod==0.19.5 transformers==3.0.2\n",
    "!pip install numpy tqdm\n",
    "!pip install torchvision torchaudio numpy tqdm transformers scikit-learn pickle5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'InterpolationMode' from 'torchvision.transforms' (/Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./PLM-NR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODEL_CLASSES\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtnlrv3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_tnlrv3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TuringNLRv3Tokenizer\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/DeepL-Project/./PLM-NR/utils.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtnlrv3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TuringNLRv3ForSequenceClassification\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtnlrv3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_tnlrv3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TuringNLRv3Config\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtnlrv3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_tnlrv3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TuringNLRv3Tokenizer\n",
      "File \u001b[0;32m~/Desktop/DeepLearning/DeepL-Project/./PLM-NR/tnlrv3/modeling.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Loss\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_bert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     BertPreTrainedModel, BertSelfOutput, BertIntermediate, \n\u001b[1;32m     13\u001b[0m     BertOutput, BertPredictionHeadTransform, BertPooler\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# from transformers.modeling_bert import \\\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     BertPreTrainedModel, BertSelfOutput, BertIntermediate, \\\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     BertOutput, BertPredictionHeadTransform, BertPooler\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WEIGHTS_NAME\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:47\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     _prepare_4d_attention_mask_for_sdpa,\n\u001b[1;32m     34\u001b[0m     _prepare_4d_causal_attention_mask_for_sdpa,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     37\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[1;32m     38\u001b[0m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     50\u001b[0m     ModelOutput,\n\u001b[1;32m     51\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     57\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py:48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenerationConfig, GenerationMixin\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     Conv1D,\n\u001b[1;32m     51\u001b[0m     apply_chunking_to_forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     prune_linear_layer,\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoHfQuantizer, HfQuantizer\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/loss/loss_utils.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_deformable_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForObjectDetectionLoss, ForSegmentationLoss\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_rt_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDetrForObjectDetectionLoss\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/loss/loss_deformable_detr.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scipy_available\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     HungarianMatcher,\n\u001b[1;32m      8\u001b[0m     ImageLoss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     sigmoid_focal_loss,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/image_transforms.py:22\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable, List, Optional, Tuple, Union\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     ChannelDimension,\n\u001b[1;32m     24\u001b[0m     ImageInput,\n\u001b[1;32m     25\u001b[0m     get_channel_dimension_axis,\n\u001b[1;32m     26\u001b[0m     get_image_size,\n\u001b[1;32m     27\u001b[0m     infer_channel_dimension_format,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     is_flax_available,\n\u001b[1;32m     32\u001b[0m     is_tf_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     requires_backends,\n\u001b[1;32m     38\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/image_utils.py:58\u001b[0m\n\u001b[1;32m     55\u001b[0m         PILImageResampling \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[1;32m     60\u001b[0m         pil_torch_interpolation_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     61\u001b[0m             PILImageResampling\u001b[38;5;241m.\u001b[39mNEAREST: InterpolationMode\u001b[38;5;241m.\u001b[39mNEAREST,\n\u001b[1;32m     62\u001b[0m             PILImageResampling\u001b[38;5;241m.\u001b[39mBOX: InterpolationMode\u001b[38;5;241m.\u001b[39mBOX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m             PILImageResampling\u001b[38;5;241m.\u001b[39mLANCZOS: InterpolationMode\u001b[38;5;241m.\u001b[39mLANCZOS,\n\u001b[1;32m     67\u001b[0m         }\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'InterpolationMode' from 'torchvision.transforms' (/Users/c-hasselris/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sys.path.insert(0, './PLM-NR')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from utils import MODEL_CLASSES\n",
    "from tnlrv3.tokenization_tnlrv3 import TuringNLRv3Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c-hasselris/DeepL/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2107: FutureWarning: Calling TuringNLRv3Tokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#path_turing = './tnlrv3'\n",
    "tokenizer = TuringNLRv3Tokenizer.from_pretrained(\"/Users/c-hasselris/Desktop/DeepLearning/DeepL-Project/unilm2/tokenizer/unilm2-base-uncased-vocab.txt\",\n",
    "                                                 do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.news_query_vector_dim = 200\n",
    "        self.drop_rate = 0.2\n",
    "        self.news_dim = 256\n",
    "        self.T = 500\n",
    "        self.corpus_path = './docs_filter.tsv'\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TITLE_LEN = 24\n",
    "MAX_BODY_LEN = 512\n",
    "NPRATIO=1\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(args.corpus_path, encoding='utf-8') as f:\n",
    "    total_lines = f.readlines()\n",
    "len(total_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, bodies = ['behaviors_np4'], [0]\n",
    "for line in total_lines:\n",
    "    splited = line.strip('\\n').split('\\t')\n",
    "    titles.append(splited[3])\n",
    "    bodies.append(splited[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self, titles, bodies):\n",
    "        self.titles = titles\n",
    "        self.bodies = bodies\n",
    "        self.len = len(titles)\n",
    "        \n",
    "    # def __getitem__(self, idx):\n",
    "    #     select_list = list(range(0, idx)) + list(range(idx+1, self.len))\n",
    "    #     neg_idx = random.sample(select_list, NPRATIO)\n",
    "    #     neg_titles = [self.titles[i] for i in neg_idx]\n",
    "    #     pos_title = self.titles[idx]\n",
    "    #     titles = [tokenizer(title, max_length=MAX_TITLE_LEN, pad_to_max_length=True,\n",
    "    #                         truncation=True) for title in [pos_title] + neg_titles]\n",
    "    #     input_titles = np.array([title['input_ids'] + title['attention_mask'] for title in titles])\n",
    "    #     body = tokenizer(self.bodies[idx], max_length=MAX_BODY_LEN, pad_to_max_length=True,\n",
    "    #                      truncation=True)\n",
    "    #     input_body = np.array(body['input_ids'] + body['attention_mask'])\n",
    "\n",
    "    #     label=0\n",
    "    #     return input_titles, input_body, label\n",
    "class PretrainDataset:\n",
    "    def __init__(self, titles, bodies):\n",
    "        self.titles = titles\n",
    "        self.bodies = bodies\n",
    "        self.len = len(titles)  # Ensure len is an integer representing the length of the dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        select_list = list(range(0, idx)) + list(range(idx + 1, self.len))\n",
    "        if len(select_list) < NPRATIO:\n",
    "            raise ValueError(\"NPRATIO is larger than the available population.\")\n",
    "        neg_idx = random.sample(select_list, NPRATIO)\n",
    "        neg_titles = [self.titles[i] for i in neg_idx]\n",
    "        pos_title = self.titles[idx]\n",
    "        return pos_title, neg_titles\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_ds = PretrainDataset(titles, bodies)\n",
    "pretrain_dl = DataLoader(pretrain_ds, batch_size=BATCH_SIZE, num_workers=0, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(emb_size, hidden_size)\n",
    "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch_size, candidate_size, emb_dim\n",
    "            attn_mask: batch_size, candidate_size\n",
    "        Returns:\n",
    "            (shape) batch_size, emb_dim\n",
    "        \"\"\"\n",
    "        bz = x.shape[0]\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "        alpha = torch.exp(alpha)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "        \n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha).squeeze(dim=-1)\n",
    "        return x\n",
    "\n",
    "class NewsEncoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(NewsEncoder, self).__init__()\n",
    "        config_class, model_class, tokenizer_class = MODEL_CLASSES['tnlrv3']\n",
    "        self.bert_config = config_class.from_pretrained(\n",
    "            \"/Users/c-hasselris/Desktop/DeepLearning/DeepL-Project/unilm2/config/unilm2-base-uncased-config.json\", \n",
    "            output_hidden_states=True,\n",
    "            num_hidden_layers=12)\n",
    "        self.bert_model = model_class.from_pretrained(\n",
    "            \"/Users/c-hasselris/Desktop/DeepLearning/DeepL-Project/unilm2/unilm2-base-uncased.bin\", config=self.bert_config)\n",
    "        self.attn = AttentionPooling(self.bert_config.hidden_size, args.news_query_vector_dim)\n",
    "        self.dense = nn.Linear(self.bert_config.hidden_size, args.news_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x: batch_size, word_num * 2\n",
    "            mask: batch_size, word_num\n",
    "        '''\n",
    "        batch_size, num_words = x.shape\n",
    "        num_words = num_words // 2\n",
    "        text_ids = torch.narrow(x, 1, 0, num_words)\n",
    "        text_attmask = torch.narrow(x, 1, num_words, num_words)\n",
    "        word_vecs = self.bert_model(text_ids, text_attmask)[3][self.bert_config.num_hidden_layers]\n",
    "        news_vec = self.attn(word_vecs)\n",
    "        news_vec = self.dense(news_vec)\n",
    "        return news_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleBodySimModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(TitleBodySimModel, self).__init__()\n",
    "        self.news_encoder = NewsEncoder(args)\n",
    "        self.loss = nn.CrossEntropyLoss() \n",
    "        \n",
    "    def forward(self, title, body, labels):\n",
    "        '''\n",
    "            title: bz, 1+K, MAX_TITLE_WORD * 2\n",
    "            body: bz, MAX_BODY_WORD * 2\n",
    "            labels: bz\n",
    "        '''\n",
    "        body_emb = self.news_encoder(body)             #bz,emb_dim\n",
    "        bz, candi_num, input_num = title.shape\n",
    "        title = title.reshape(-1, input_num)\n",
    "        title_emb = self.news_encoder(title)\n",
    "        title_emb = title_emb.reshape(bz, candi_num, -1) #bz, 1+K, emb_dim\n",
    "        \n",
    "        scores = torch.bmm(title_emb, body_emb.unsqueeze(dim=-1)).squeeze(-1)\n",
    "        \n",
    "        loss = self.loss(scores, labels)\n",
    "        return scores, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c-hasselris/Desktop/DeepLearning/DeepL-Project/PLM-NR/tnlrv3/modeling.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n",
      "Some weights of TuringNLRv3ForSequenceClassification were not initialized from the model checkpoint at /Users/c-hasselris/Desktop/DeepLearning/DeepL-Project/unilm2/unilm2-base-uncased.bin and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TitleBodySimModel(\n",
       "  (news_encoder): NewsEncoder(\n",
       "    (bert_model): TuringNLRv3ForSequenceClassification(\n",
       "      (bert): TuringNLRv3Model(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "        (rel_pos_bias): Linear(in_features=32, out_features=12, bias=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "    (attn): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=768, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "    (dense): Linear(in_features=768, out_features=256, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_model = TitleBodySimModel(args)\n",
    "device = torch.device('cpu')\n",
    "pretrain_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = torch.argmax(y_hat, dim=-1)\n",
    "    tot = y_true.shape[0]\n",
    "    hit = torch.sum(y_true == y_hat)\n",
    "    return hit.data.float() * 1.0 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_encoder.bert_model.bert.embeddings.word_embeddings.weight False\n",
      "news_encoder.bert_model.bert.embeddings.position_embeddings.weight False\n",
      "news_encoder.bert_model.bert.embeddings.token_type_embeddings.weight False\n",
      "news_encoder.bert_model.bert.embeddings.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.embeddings.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.self.query.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.self.query.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.self.key.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.self.key.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.self.value.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.self.value.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.intermediate.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.intermediate.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.0.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.self.query.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.self.query.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.self.key.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.self.key.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.self.value.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.self.value.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.intermediate.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.intermediate.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.1.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.self.query.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.self.query.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.self.key.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.self.key.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.self.value.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.self.value.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.intermediate.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.intermediate.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.2.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.self.query.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.self.query.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.self.key.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.self.key.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.self.value.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.self.value.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.intermediate.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.intermediate.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.3.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.self.query.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.self.query.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.self.key.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.self.key.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.self.value.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.self.value.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.intermediate.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.intermediate.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.4.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.self.query.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.self.query.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.self.key.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.self.key.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.self.value.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.self.value.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.intermediate.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.intermediate.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.5.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.self.query.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.self.query.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.self.key.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.self.key.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.self.value.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.self.value.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.attention.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.intermediate.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.intermediate.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.6.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.self.query.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.self.query.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.self.key.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.self.key.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.self.value.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.self.value.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.attention.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.intermediate.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.intermediate.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.7.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.self.query.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.self.query.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.self.key.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.self.key.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.self.value.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.self.value.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.attention.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.intermediate.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.intermediate.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.output.dense.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.output.dense.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.output.LayerNorm.weight False\n",
      "news_encoder.bert_model.bert.encoder.layer.8.output.LayerNorm.bias False\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.self.query.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.self.query.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.self.key.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.self.key.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.self.value.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.self.value.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.output.dense.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.output.dense.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.intermediate.dense.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.intermediate.dense.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.output.dense.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.output.dense.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.output.LayerNorm.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.9.output.LayerNorm.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.self.query.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.self.query.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.self.key.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.self.key.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.self.value.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.self.value.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.output.dense.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.output.dense.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.intermediate.dense.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.intermediate.dense.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.output.dense.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.output.dense.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.output.LayerNorm.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.10.output.LayerNorm.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.self.query.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.self.query.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.self.key.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.self.key.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.self.value.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.self.value.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.output.dense.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.output.dense.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.intermediate.dense.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.intermediate.dense.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.output.dense.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.output.dense.bias True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.output.LayerNorm.weight True\n",
      "news_encoder.bert_model.bert.encoder.layer.11.output.LayerNorm.bias True\n",
      "news_encoder.bert_model.bert.pooler.dense.weight False\n",
      "news_encoder.bert_model.bert.pooler.dense.bias False\n",
      "news_encoder.bert_model.bert.rel_pos_bias.weight False\n",
      "news_encoder.bert_model.classifier.weight False\n",
      "news_encoder.bert_model.classifier.bias False\n",
      "news_encoder.attn.att_fc1.weight True\n",
      "news_encoder.attn.att_fc1.bias True\n",
      "news_encoder.attn.att_fc2.weight True\n",
      "news_encoder.attn.att_fc2.bias True\n",
      "news_encoder.dense.weight True\n",
      "news_encoder.dense.bias True\n"
     ]
    }
   ],
   "source": [
    "for param in pretrain_model.news_encoder.bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for index, layer in enumerate(pretrain_model.news_encoder.bert_model.bert.encoder.layer):\n",
    "    if index in [9, 10, 11]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "for name, p in pretrain_model.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_param = filter(\n",
    "    lambda x: id(x) not in list(map(id, pretrain_model.news_encoder.bert_model.parameters())), pretrain_model.parameters())\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    [{'params':pretrain_model.news_encoder.bert_model.parameters(),'lr':1e-6},\n",
    "    {'params':rest_param,'lr':1e-5}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^    ^exitcode = _main(fd, parent_sentinel)\n",
      "^^^^^^^^^^^^^\n",
      "     File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^self = reduction.pickle.load(from_parent)\n",
      "^^\n",
      "AttributeError :  Can't get attribute 'PretrainDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>  \n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'PretrainDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'PretrainDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'PretrainDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  0%|          | 0/1 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/2n/l9c3frpx6t75jryh87_5ptzc0000gn/T/ipykernel_84236/2043565501.py\", line 7, in <module>\n",
      "    for title,body,labels in tqdm_util:\n",
      "                            ^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1448, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1412, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1243, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 84295) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1153, in get_records\n",
      "    mod = inspect.getmodule(cf.tb_frame)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py\", line 1006, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/c-hasselris/DeepL/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 84297) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    }
   ],
   "source": [
    "for ep in range(1):\n",
    "    loss = 0.0\n",
    "    accuary = 0.0\n",
    "    cnt = 1\n",
    "    tqdm_util = tqdm(pretrain_dl)\n",
    "    pretrain_model.train()\n",
    "    for title,body,labels in tqdm_util: \n",
    "        title = title.to(device)\n",
    "        body = body.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        y_hat, bz_loss = pretrain_model(title, body, labels)\n",
    "        loss += bz_loss.data.float()\n",
    "        accuary += acc(labels, y_hat)\n",
    "        optimizer.zero_grad()\n",
    "        bz_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if cnt % 10 == 0:\n",
    "            tqdm_util.set_description('ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(cnt * BATCH_SIZE, loss.data / cnt, accuary / cnt))\n",
    "\n",
    "        if cnt % args.T == 0:\n",
    "            ckpt_path = f'./DP_12_layer_{cnt}.pt'\n",
    "            torch.save({'model_state_dict': pretrain_model.state_dict()}, ckpt_path)\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "ckpt_path = './DP_12_layer.pt'\n",
    "torch.save({'model_state_dict': pretrain_model.state_dict()}, ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Title and Body Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_paths = [\n",
    "    './DP_12_layer.pt',\n",
    "    './DP_12_layer_61500.pt',\n",
    "    './DP_12_layer_61000.pt',\n",
    "    './DP_12_layer_60500.pt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data, max_len):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        res = tokenizer(self.data[idx], max_length=self.max_len, pad_to_max_length=True, truncation=True)\n",
    "        return np.array(res['input_ids'] + res['attention_mask'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "title_dataset = NewsDataset(titles, MAX_TITLE_LEN)\n",
    "title_dataloader = DataLoader(title_dataset,\n",
    "                            batch_size=512,\n",
    "                            num_workers=0)\n",
    "\n",
    "body_dataset = NewsDataset(bodies, MAX_BODY_LEN)\n",
    "body_dataloader = DataLoader(body_dataset,\n",
    "                            batch_size=512,\n",
    "                            num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ckpt_path in enumerate(ckpt_paths):\n",
    "    pretrain_model.load_state_dict(torch.load(ckpt_path))\n",
    "    title_scoring = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids in tqdm(title_dataloader):\n",
    "            input_ids = input_ids.cuda()\n",
    "            news_vec = pretrain_model.news_encoder(input_ids)\n",
    "            news_vec = news_vec.to(torch.device(\"cpu\")).detach().numpy()\n",
    "            title_scoring.extend(news_vec)\n",
    "\n",
    "    title_scoring = np.array(title_scoring)\n",
    "    with open(f'./teacher_title_emb_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(title_scoring, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ckpt_path in enumerate(ckpt_paths):\n",
    "    pretrain_model.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "    body_scoring = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids in tqdm(body_dataloader):\n",
    "            input_ids = input_ids.cuda()\n",
    "            news_vec = pretrain_model.news_encoder(input_ids)\n",
    "            news_vec = news_vec.to(torch.device(\"cpu\")).detach().numpy()\n",
    "            body_scoring.extend(news_vec)\n",
    "\n",
    "    body_scoring = np.array(body_scoring)\n",
    "    with open(f'./teacher_body_emb_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(body_scoring, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
